#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Project Dhruv â€“ OpenAI_V1 Parser
(Best-of-3 + Think-Harder Merge)

- Hindi-first taxonomy
- Best-of-3 consensus: keyword rules + old parser hint + rescue logic
- Strong focus on:
  - Reducing "à¤…à¤¨à¥à¤¯" safely
  - Keeping confidence >=0.90 only for truly strong cases
  - Better location coverage (à¤œà¤¿à¤²à¤¾, à¤¤à¤¹à¤¸à¥€à¤², à¤¥à¤¾à¤¨à¤¾, à¤µà¤¿à¤•à¤¾à¤¸à¤–à¤‚à¤¡, à¤šà¥Œà¤•à¥€...)

Usage:
  python3 parse_OpenAI_V1.py input.jsonl output.jsonl

If no args:
  input  = ../data/parsed_tweets_v52.jsonl
  output = ../data/parsed_tweets_OpenAI_V1.jsonl
"""

import json
import re
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from collections import Counter

# -------------------------
# Paths
# -------------------------

DEFAULT_INPUT = Path(__file__).parent.parent / "data" / "parsed_tweets_v52.jsonl"
DEFAULT_OUTPUT = Path(__file__).parent.parent / "data" / "parsed_tweets_OpenAI_V1.jsonl"

# -------------------------
# Taxonomies / Enums
# -------------------------

ALLOWED_EVENT_TYPES_HI = [
    "à¤¬à¥ˆà¤ à¤•",
    "à¤œà¤¨à¤¸à¤®à¥à¤ªà¤°à¥à¤• / à¤œà¤¨à¤¦à¤°à¥à¤¶à¤¨",
    "à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤¨à¤¿à¤• à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•",
    "à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£",
    "à¤°à¥ˆà¤²à¥€",
    "à¤šà¥à¤¨à¤¾à¤µ à¤ªà¥à¤°à¤šà¤¾à¤°",
    "à¤‰à¤¦à¥à¤˜à¤¾à¤Ÿà¤¨",
    "à¤¯à¥‹à¤œà¤¨à¤¾ à¤˜à¥‹à¤·à¤£à¤¾",
    "à¤§à¤¾à¤°à¥à¤®à¤¿à¤• / à¤¸à¤¾à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤• à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
    "à¤¸à¤®à¥à¤®à¤¾à¤¨ / Felicitation",
    "à¤ªà¥à¤°à¥‡à¤¸ à¤•à¥‰à¤¨à¥à¤«à¤¼à¥à¤°à¥‡à¤‚à¤¸ / à¤®à¥€à¤¡à¤¿à¤¯à¤¾",
    "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾ / à¤¬à¤§à¤¾à¤ˆ",
    "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾",
    "à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶",
    "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸",
    "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ",
    "à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
    "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾",
    "à¤…à¤¨à¥à¤¯",
]

CONTENT_MODES = [
    "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
    "à¤¨à¥€à¤¤à¤¿ / à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
    "à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² / à¤¸à¥‹à¤¶à¤²-à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤ªà¥‹à¤¸à¥à¤Ÿ",
    "à¤–à¥‡à¤² / à¤‰à¤ªà¤²à¤¬à¥à¤§à¤¿ à¤ªà¤° à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾",
    "à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤ / à¤ªà¤°à¥à¤µ",
]

# High-precision & extended keyword clusters (merged)
EVENT_KEYWORD_CLUSTERS: List[Tuple[List[str], str]] = [
    # Security
    (
        [
            "à¤®à¤¾à¤“à¤µà¤¾à¤¦", "à¤®à¤¾à¤“à¤µà¤¾à¤¦à¥€", "à¤¨à¤•à¥à¤¸à¤²", "à¤¨à¤•à¥à¤¸à¤²à¥€", "à¤²à¤¾à¤² à¤†à¤¤à¤‚à¤•", "à¤¸à¥à¤°à¤•à¥à¤·à¤¾ à¤¬à¤²",
            "à¤œà¤µà¤¾à¤¨à¥‹à¤‚", "à¤œà¤µà¤¾à¤¨", "à¤¶à¤¹à¥€à¤¦", "à¤†à¤¤à¥à¤®à¤¸à¤®à¤°à¥à¤ªà¤£", "encounter", "ied",
            "police", "à¤ªà¥à¤²à¤¿à¤¸", "à¤‰à¤—à¥à¤°à¤µà¤¾à¤¦", "à¤†à¤¤à¤‚à¤•à¤µà¤¾à¤¦"
        ],
        "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸",
    ),
    # Sports / Pride (no standalone à¤œà¥€à¤¤/à¤µà¤¿à¤œà¤¯)
    (
        [
            "à¤•à¥à¤°à¤¿à¤•à¥‡à¤Ÿ", "à¤Ÿà¥€à¤® à¤‡à¤‚à¤¡à¤¿à¤¯à¤¾", "world cup", "à¤µà¤°à¥à¤²à¥à¤¡ à¤•à¤ª", "t20", "à¤Ÿà¥€20",
            "ipl", "odi", "à¤µà¤¨à¤¡à¥‡", "bcci", "à¤°à¤£à¤œà¥€", "à¤ªà¤¦à¤•", "medal",
            "à¤¸à¥à¤µà¤°à¥à¤£ à¤ªà¤¦à¤•", "à¤°à¤œà¤¤ à¤ªà¤¦à¤•", "à¤•à¤¾à¤‚à¤¸à¥à¤¯ à¤ªà¤¦à¤•", "championship"
        ],
        "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ",
    ),
    # Disaster / Accident
    (
        [
            "à¤¹à¤¾à¤¦à¤¸à¤¾", "à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾", "à¤°à¥‡à¤² à¤¹à¤¾à¤¦à¤¸à¤¾", "à¤¬à¤¸ à¤¹à¤¾à¤¦à¤¸à¤¾", "à¤†à¤—à¤œà¤¨à¥€",
            "à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤• à¤†à¤ªà¤¦à¤¾", "à¤¬à¤¾à¤¢à¤¼", "tragedy", "accident", "collision",
            "à¤œà¤¨à¤¹à¤¾à¤¨à¤¿"
        ],
        "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾",
    ),
    # Political statement (macro)
    (
        [
            "à¤¡à¤¬à¤² à¤‡à¤‚à¤œà¤¨", "à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸ à¤¸à¤°à¤•à¤¾à¤°", "à¤­à¥à¤°à¤·à¥à¤Ÿà¤¾à¤šà¤¾à¤°", "à¤¤à¥à¤·à¥à¤Ÿà¤¿à¤•à¤°à¤£", "à¤†à¤ªà¤¾à¤¤à¤•à¤¾à¤²",
            "à¤µà¤¿à¤•à¤¸à¤¿à¤¤ à¤­à¤¾à¤°à¤¤", "à¤®à¥‹à¤¦à¥€ à¤•à¥€ à¤—à¤¾à¤°à¤‚à¤Ÿà¥€", "à¤µà¤¿à¤ªà¤•à¥à¤·", "manifesto",
            "à¤¸à¤‚à¤•à¤²à¥à¤ª à¤ªà¤¤à¥à¤°", "à¤¸à¤°à¤•à¤¾à¤° à¤•à¥€ à¤¨à¥€à¤¤à¤¿à¤¯à¤¾à¤"
        ],
        "à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
    ),
    # Classical programme types
    (["à¤¬à¥ˆà¤ à¤•", "à¤¬à¥ˆà¤ à¤• à¤²à¥€", "à¤¬à¥ˆà¤ à¤• à¤®à¥‡à¤‚", "à¤¬à¥ˆà¤ à¤• à¤•à¤¾", "à¤­à¥‡à¤‚à¤Ÿ", "à¤®à¥à¤²à¤¾à¤•à¤¾à¤¤", "à¤…à¤§à¥à¤¯à¤•à¥à¤·à¤¤à¤¾ à¤•à¥€"], "à¤¬à¥ˆà¤ à¤•"),
    (["à¤œà¤¨à¤¸à¤®à¥à¤ªà¤°à¥à¤•", "à¤œà¤¨à¤¸à¤‚à¤ªà¤°à¥à¤•", "à¤œà¤¨ à¤¸à¤‚à¤ªà¤°à¥à¤•", "à¤œà¤¨à¤¦à¤°à¥à¤¶à¤¨", "à¤œà¤¨-à¤¦à¤°à¥à¤¶à¤¨", "à¤œà¤¨ à¤¸à¥à¤¨à¤µà¤¾à¤ˆ", "à¤œà¤¨à¤¸à¥à¤¨à¤µà¤¾à¤ˆ"], "à¤œà¤¨à¤¸à¤®à¥à¤ªà¤°à¥à¤• / à¤œà¤¨à¤¦à¤°à¥à¤¶à¤¨"),
    (["à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•", "à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤•à¥€", "à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤•à¥€ à¤—à¤ˆ", "à¤…à¤§à¤¿à¤•à¤¾à¤°à¤¿à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¸à¤¾à¤¥", "à¤µà¤¿à¤­à¤¾à¤—à¥€à¤¯ à¤¬à¥ˆà¤ à¤•", "à¤•à¤²à¥‡à¤•à¥à¤Ÿà¤°", "à¤•à¤²à¥‡à¤•à¥à¤Ÿà¤°à¥‡à¤Ÿ"], "à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤¨à¤¿à¤• à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•"),
    (["à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£", "à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£ à¤•à¤¿à¤¯à¤¾", "inspection"], "à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£"),
    (["à¤°à¥ˆà¤²à¥€", "à¤œà¤¨à¤¸à¤­à¤¾", "public rally", "à¤°à¥‹à¤¡ à¤¶à¥‹", "road show"], "à¤°à¥ˆà¤²à¥€"),
    (["à¤šà¥à¤¨à¤¾à¤µà¥€", "à¤®à¤¤à¤¦à¤¾à¤¤à¤¾", "à¤®à¤¤à¤¦à¤¾à¤¨", "à¤µà¥‹à¤Ÿ", "à¤ªà¥à¤°à¤šà¤¾à¤°", "poll campaign", "voting", "polling", "à¤•à¥ˆà¤‚à¤ªà¥‡à¤¨"], "à¤šà¥à¤¨à¤¾à¤µ à¤ªà¥à¤°à¤šà¤¾à¤°"),
    (["à¤‰à¤¦à¥à¤˜à¤¾à¤Ÿà¤¨", "à¤²à¥‹à¤•à¤¾à¤°à¥à¤ªà¤£", "inauguration", "inaugurated", "à¤¶à¤¿à¤²à¤¾à¤¨à¥à¤¯à¤¾à¤¸", "dedication"], "à¤‰à¤¦à¥à¤˜à¤¾à¤Ÿà¤¨"),
    (["à¤˜à¥‹à¤·à¤£à¤¾", "à¤¨à¤ˆ à¤¯à¥‹à¤œà¤¨à¤¾", "à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€", "à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¤¾ à¤²à¤¾à¤­", "scheme launch"], "à¤¯à¥‹à¤œà¤¨à¤¾ à¤˜à¥‹à¤·à¤£à¤¾"),
    (["à¤®à¤‚à¤¦à¤¿à¤°", "à¤ªà¥‚à¤œà¤¾", "à¤†à¤°à¤¤à¥€", "à¤—à¥à¤°à¥à¤¦à¥à¤µà¤¾à¤°à¤¾", "à¤®à¤¸à¥à¤œà¤¿à¤¦", "à¤§à¤¾à¤°à¥à¤®à¤¿à¤•", "à¤¸à¤¾à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤• à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®", "à¤œà¤¯à¤‚à¤¤à¥€", "à¤®à¤¹à¥‹à¤¤à¥à¤¸à¤µ", "à¤ªà¤°à¥à¤µ"], "à¤§à¤¾à¤°à¥à¤®à¤¿à¤• / à¤¸à¤¾à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤• à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®"),
    (["à¤¸à¤®à¥à¤®à¤¾à¤¨", "à¤¸à¤®à¥à¤®à¤¾à¤¨à¤¿à¤¤", "à¤¶à¥‰à¤²", "à¤¶à¥à¤°à¥€à¤«à¤²", "felicitation", "award", "à¤¸à¤®à¥à¤®à¤¾à¤¨ à¤¸à¤®à¤¾à¤°à¥‹à¤¹"], "à¤¸à¤®à¥à¤®à¤¾à¤¨ / Felicitation"),
    (["à¤ªà¥à¤°à¥‡à¤¸ à¤µà¤¾à¤°à¥à¤¤à¤¾", "à¤ªà¥à¤°à¥‡à¤¸ à¤•à¥‰à¤¨à¥à¤«à¤¼à¥à¤°à¥‡à¤‚à¤¸", "à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤¸à¥‡ à¤¬à¤¾à¤¤à¤šà¥€à¤¤", "à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤¬à¥à¤°à¤¿à¤«à¤¿à¤‚à¤—", "pc"], "à¤ªà¥à¤°à¥‡à¤¸ à¤•à¥‰à¤¨à¥à¤«à¤¼à¥à¤°à¥‡à¤‚à¤¸ / à¤®à¥€à¤¡à¤¿à¤¯à¤¾"),
    (["à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤‚", "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤", "à¤¬à¤§à¤¾à¤ˆ", "congratulations", "best wishes", "greetings", "à¤®à¥à¤¬à¤¾à¤°à¤•"], "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾ / à¤¬à¤§à¤¾à¤ˆ"),
    (["à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨", "birthday", "à¤…à¤µà¤¤à¤°à¤£ à¤¦à¤¿à¤µà¤¸"], "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾"),
    (["à¤¶à¥à¤°à¤¦à¥à¤§à¤¾à¤‚à¤œà¤²à¤¿", "à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶", "à¤¦à¤¿à¤µà¤‚à¤—à¤¤", "à¤…à¤‚à¤¤à¤¿à¤® à¤¯à¤¾à¤¤à¥à¤°à¤¾", "à¤ªà¥à¤£à¥à¤¯à¤¤à¤¿à¤¥à¤¿", "condolence", "tribute", "rip"], "à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶"),
]

SCHEME_PATTERNS = {
    r"\bPMAY\b": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤ªà¥à¤°à¤§à¤¾à¤¨ à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"PM Awas": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤": "à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤",
    r"\bAyushman\b": "à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤",
    r"à¤‰à¤œà¥à¤œà¥à¤µà¤²à¤¾ à¤¯à¥‹à¤œà¤¨à¤¾": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤‰à¤œà¤¸à¥à¤¼à¤µà¤²à¤¾ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤¸à¥à¤µà¤šà¥à¤› à¤­à¤¾à¤°à¤¤": "à¤¸à¥à¤µà¤šà¥à¤› à¤­à¤¾à¤°à¤¤ à¤®à¤¿à¤¶à¤¨",
    r"à¤œà¤¨ à¤§à¤¨": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤œà¤¨ à¤§à¤¨ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"\bGST\b": "GST",
}

TARGET_GROUP_KEYWORDS = {
    "à¤®à¤¹à¤¿à¤²à¤¾": "à¤®à¤¹à¤¿à¤²à¤¾",
    "à¤®à¤¹à¤¿à¤²à¤¾à¤“à¤‚": "à¤®à¤¹à¤¿à¤²à¤¾",
    "à¤¨à¤¾à¤°à¥€": "à¤®à¤¹à¤¿à¤²à¤¾",
    "à¤¯à¥à¤µà¤¾": "à¤¯à¥à¤µà¤¾",
    "à¤¯à¥à¤µà¤¾à¤“à¤‚": "à¤¯à¥à¤µà¤¾",
    "à¤•à¤¿à¤¸à¤¾à¤¨": "à¤•à¤¿à¤¸à¤¾à¤¨",
    "à¤•à¤¿à¤¸à¤¾à¤¨à¥‹à¤‚": "à¤•à¤¿à¤¸à¤¾à¤¨",
    "à¤–à¥‡à¤¤à¥€": "à¤•à¤¿à¤¸à¤¾à¤¨",
    "à¤›à¤¾à¤¤à¥à¤°": "à¤›à¤¾à¤¤à¥à¤°",
    "à¤µà¤¿à¤¦à¥à¤¯à¤¾à¤°à¥à¤¥à¥€": "à¤›à¤¾à¤¤à¥à¤°",
    "à¤¸à¥à¤Ÿà¥‚à¤¡à¥‡à¤‚à¤Ÿ": "à¤›à¤¾à¤¤à¥à¤°",
    "à¤®à¤œà¤¦à¥‚à¤°": "à¤®à¤œà¤¼à¤¦à¥‚à¤°",
    "à¤®à¤œà¤¦à¥‚à¤°à¥‹à¤‚": "à¤®à¤œà¤¼à¤¦à¥‚à¤°",
    "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°à¥€": "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°à¥€",
    "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°à¤¿à¤¯à¥‹à¤‚": "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°à¥€",
    "à¤—à¤°à¥€à¤¬": "à¤—à¤°à¥€à¤¬",
    "à¤†à¤°à¥à¤¥à¤¿à¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤•à¤®à¤œà¥‹à¤°": "à¤—à¤°à¥€à¤¬",
    "à¤¬à¥à¤œà¥à¤°à¥à¤—": "à¤¬à¥à¤œà¤¼à¥à¤°à¥à¤—",
    "à¤µà¤°à¤¿à¤·à¥à¤  à¤¨à¤¾à¤—à¤°à¤¿à¤•": "à¤¬à¥à¤œà¤¼à¥à¤°à¥à¤—",
    "à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤•à¤°à¥à¤®à¤šà¤¾à¤°à¥€": "à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤•à¤°à¥à¤®à¤šà¤¾à¤°à¥€",
    "à¤¶à¤¾à¤¸à¤•à¥€à¤¯ à¤•à¤°à¥à¤®à¤šà¤¾à¤°à¥€": "à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤•à¤°à¥à¤®à¤šà¤¾à¤°à¥€",
}

COMMUNITY_KEYWORDS = {
    "à¤¸à¤¾à¤¹à¥‚": "à¤¸à¤¾à¤¹à¥‚",
    "à¤—à¥‹à¤‚à¤¡": "à¤—à¥‹à¤‚à¤¡",
    "à¤†à¤¦à¤¿à¤µà¤¾à¤¸à¥€": "à¤†à¤¦à¤¿à¤µà¤¾à¤¸à¥€",
    "à¤—à¥‹à¤‚à¤¡à¤µà¤¾à¤¨à¤¾": "à¤—à¥‹à¤‚à¤¡",
    "à¤µà¥ˆà¤¶à¥à¤¯": "à¤µà¥ˆà¤¶à¥à¤¯",
    "à¤¬à¥à¤°à¤¾à¤¹à¥à¤®à¤£": "à¤¬à¥à¤°à¤¾à¤¹à¥à¤®à¤£",
    "à¤•à¥à¤°à¥à¤®à¥€": "à¤•à¥à¤°à¥à¤®à¥€",
    "à¤¤à¥‡à¤²à¥€": "à¤¤à¥‡à¤²à¥€",
    "à¤ à¤¾à¤•à¥à¤°": "à¤ à¤¾à¤•à¥à¤°",
    "à¤•à¥à¤¶à¤µà¤¾à¤¹à¤¾": "à¤•à¥à¤¶à¤µà¤¾à¤¹à¤¾",
    "à¤¦à¤²à¤¿à¤¤": "à¤¦à¤²à¤¿à¤¤",
    "à¤…à¤¨à¥à¤¸à¥‚à¤šà¤¿à¤¤ à¤œà¤¾à¤¤à¤¿": "à¤…à¤¨à¥à¤¸à¥‚à¤šà¤¿à¤¤ à¤œà¤¾à¤¤à¤¿",
    "à¤…à¤¨à¥à¤¸à¥‚à¤šà¤¿à¤¤ à¤œà¤¨à¤œà¤¾à¤¤à¤¿": "à¤…à¤¨à¥à¤¸à¥‚à¤šà¤¿à¤¤ à¤œà¤¨à¤œà¤¾à¤¤à¤¿",
    "à¤“à¤¬à¥€à¤¸à¥€": "à¤“à¤¬à¥€à¤¸à¥€",
    "à¤®à¥à¤¸à¥à¤²à¤¿à¤®": "à¤®à¥à¤¸à¥à¤²à¤¿à¤®",
    "à¤ˆà¤¸à¤¾à¤ˆ": "à¤ˆà¤¸à¤¾à¤ˆ",
    "à¤•à¥à¤°à¤¿à¤¶à¥à¤šà¤¿à¤¯à¤¨": "à¤ˆà¤¸à¤¾à¤ˆ",
    "à¤¸à¤¿à¤–": "à¤¸à¤¿à¤–",
    "à¤œà¥ˆà¤¨": "à¤œà¥ˆà¤¨",
    "à¤¬à¥Œà¤¦à¥à¤§": "à¤¬à¥Œà¤¦à¥à¤§",
}

ORG_KEYWORDS = {
    "à¤­à¤¾à¤œà¤ªà¤¾": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤œà¤¨à¤¤à¤¾ à¤ªà¤¾à¤°à¥à¤Ÿà¥€",
    "BJP": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤œà¤¨à¤¤à¤¾ à¤ªà¤¾à¤°à¥à¤Ÿà¥€",
    "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤œà¤¨à¤¤à¤¾ à¤ªà¤¾à¤°à¥à¤Ÿà¥€": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤œà¤¨à¤¤à¤¾ à¤ªà¤¾à¤°à¥à¤Ÿà¥€",
    "à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸",
    "INC": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸",
    "Indian National Congress": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸",
    "RSS": "à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤¸à¥à¤µà¤¯à¤‚à¤¸à¥‡à¤µà¤• à¤¸à¤‚à¤˜",
    "à¤†à¤°à¤à¤¸à¤à¤¸": "à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤¸à¥à¤µà¤¯à¤‚à¤¸à¥‡à¤µà¤• à¤¸à¤‚à¤˜",
    "à¤•à¥‡à¤‚à¤¦à¥à¤° à¤¸à¤°à¤•à¤¾à¤°": "à¤•à¥‡à¤‚à¤¦à¥à¤° à¤¸à¤°à¤•à¤¾à¤°",
    "à¤°à¤¾à¤œà¥à¤¯ à¤¸à¤°à¤•à¤¾à¤°": "à¤°à¤¾à¤œà¥à¤¯ à¤¸à¤°à¤•à¤¾à¤°",
    "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤¸à¥‡à¤¨à¤¾": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤¸à¥‡à¤¨à¤¾",
    "Indian Army": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤¸à¥‡à¤¨à¤¾",
}

# -------------------------
# Canonical locations (merged)
# -------------------------

CANONICAL_LOCATIONS: Dict[str, Dict[str, Any]] = {
    "à¤°à¤¾à¤¯à¤—à¤¢à¤¼": {"canonical": "à¤°à¤¾à¤¯à¤—à¤¢à¤¼", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¤¢à¤¼ à¤œà¤¿à¤²à¤¾"]},
    "Raigarh": {"canonical": "à¤°à¤¾à¤¯à¤—à¤¢à¤¼", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¤¢à¤¼ à¤œà¤¿à¤²à¤¾"]},
    "à¤–à¤°à¤¸à¤¿à¤¯à¤¾": {"canonical": "à¤–à¤°à¤¸à¤¿à¤¯à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¤¢à¤¼ à¤œà¤¿à¤²à¤¾", "à¤–à¤°à¤¸à¤¿à¤¯à¤¾ à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾"]},
    "Kharsia": {"canonical": "à¤–à¤°à¤¸à¤¿à¤¯à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¤¢à¤¼ à¤œà¤¿à¤²à¤¾", "à¤–à¤°à¤¸à¤¿à¤¯à¤¾ à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾"]},
    "à¤°à¤¾à¤¯à¤ªà¥à¤°": {"canonical": "à¤°à¤¾à¤¯à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Raipur": {"canonical": "à¤°à¤¾à¤¯à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤¨à¤¯à¤¾ à¤°à¤¾à¤¯à¤ªà¥à¤°": {"canonical": "à¤¨à¤¯à¤¾ à¤°à¤¾à¤¯à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "New Raipur": {"canonical": "à¤¨à¤¯à¤¾ à¤°à¤¾à¤¯à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤°": {"canonical": "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Bilaspur": {"canonical": "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤•à¥‹à¤°à¤¬à¤¾": {"canonical": "à¤•à¥‹à¤°à¤¬à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤°à¤¬à¤¾ à¤œà¤¿à¤²à¤¾"]},
    "Korba": {"canonical": "à¤•à¥‹à¤°à¤¬à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤°à¤¬à¤¾ à¤œà¤¿à¤²à¤¾"]},
    "à¤°à¤¤à¤¨à¤ªà¥à¤°": {"canonical": "à¤°à¤¤à¤¨à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤¦à¥à¤°à¥à¤—": {"canonical": "à¤¦à¥à¤°à¥à¤—", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¥à¤°à¥à¤— à¤œà¤¿à¤²à¤¾"]},
    "Durg": {"canonical": "à¤¦à¥à¤°à¥à¤—", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¥à¤°à¥à¤— à¤œà¤¿à¤²à¤¾"]},
    "à¤­à¤¿à¤²à¤¾à¤ˆ": {"canonical": "à¤­à¤¿à¤²à¤¾à¤ˆ", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¥à¤°à¥à¤— à¤œà¤¿à¤²à¤¾"]},
    "Bhilai": {"canonical": "à¤­à¤¿à¤²à¤¾à¤ˆ", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¥à¤°à¥à¤— à¤œà¤¿à¤²à¤¾"]},
    "à¤…à¤‚à¤¬à¤¿à¤•à¤¾à¤ªà¥à¤°": {"canonical": "à¤…à¤‚à¤¬à¤¿à¤•à¤¾à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤°à¤œà¤ªà¥à¤°/à¤¸à¤°à¤—à¥à¤œà¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤°"]},
    "Ambikapur": {"canonical": "à¤…à¤‚à¤¬à¤¿à¤•à¤¾à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤°à¤œà¤ªà¥à¤°/à¤¸à¤°à¤—à¥à¤œà¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤°"]},
    "à¤¸à¥à¤°à¤œà¤ªà¥à¤°": {"canonical": "à¤¸à¥à¤°à¤œà¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤°à¤œà¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Surajpur": {"canonical": "à¤¸à¥à¤°à¤œà¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤°à¤œà¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤œà¤—à¤¦à¤²à¤ªà¥à¤°": {"canonical": "à¤œà¤—à¤¦à¤²à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¸à¥à¤¤à¤° à¤œà¤¿à¤²à¤¾"]},
    "Jagdalpur": {"canonical": "à¤œà¤—à¤¦à¤²à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¸à¥à¤¤à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ": {"canonical": "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ à¤œà¤¿à¤²à¤¾"]},
    "Kondagaon": {"canonical": "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ à¤œà¤¿à¤²à¤¾"]},
    "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤°": {"canonical": "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Narayanpur": {"canonical": "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°": {"canonical": "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°-à¤šà¤‚à¤ªà¤¾ à¤œà¤¿à¤²à¤¾"]},
    "Janjgir": {"canonical": "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°-à¤šà¤‚à¤ªà¤¾ à¤œà¤¿à¤²à¤¾"]},
    "à¤šà¤‚à¤ªà¤¾": {"canonical": "à¤šà¤‚à¤ªà¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°-à¤šà¤‚à¤ªà¤¾ à¤œà¤¿à¤²à¤¾"]},
    "à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ": {"canonical": "à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ à¤œà¤¿à¤²à¤¾"]},
    "Mahasamund": {"canonical": "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦ à¤œà¤¿à¤²à¤¾"]},
    "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦": {"canonical": "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦ à¤œà¤¿à¤²à¤¾"]},
    "à¤§à¤®à¤¤à¤°à¥€": {"canonical": "à¤§à¤®à¤¤à¤°à¥€", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤§à¤®à¤¤à¤°à¥€ à¤œà¤¿à¤²à¤¾"]},
    "Dhamtari": {"canonical": "à¤§à¤®à¤¤à¤°à¥€", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤§à¤®à¤¤à¤°à¥€ à¤œà¤¿à¤²à¤¾"]},
    "à¤¬à¤¾à¤²à¥‹à¤¦": {"canonical": "à¤¬à¤¾à¤²à¥‹à¤¦", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¾à¤²à¥‹à¤¦à¤œà¤¿à¤²à¤¾"]},
    "Balod": {"canonical": "à¤¬à¤¾à¤²à¥‹à¤¦", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¾à¤²à¥‹à¤¦à¤œà¤¿à¤²à¤¾"]},
    "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦": {"canonical": "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦ à¤œà¤¿à¤²à¤¾"]},
    "Gariaband": {"canonical": "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦ à¤œà¤¿à¤²à¤¾"]},
    "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤°": {"canonical": "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Bijapur": {"canonical": "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾": {"canonical": "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾ à¤œà¤¿à¤²à¤¾"]},
    "Dantewada": {"canonical": "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾ à¤œà¤¿à¤²à¤¾"]},
    "à¤¸à¥à¤•à¤®à¤¾": {"canonical": "à¤¸à¥à¤•à¤®à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤•à¤®à¤¾à¤œà¤¿à¤²à¤¾"]},
    "Sukma": {"canonical": "à¤¸à¥à¤•à¤®à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤•à¤®à¤¾à¤œà¤¿à¤²à¤¾"]},
    # Newer districts / splits
    "à¤¬à¤²à¥Œà¤¦à¤¾à¤¬à¤¾à¤œà¤¾à¤°": {"canonical": "à¤¬à¤²à¥Œà¤¦à¤¾à¤¬à¤¾à¤œà¤¾à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤²à¥Œà¤¦à¤¾à¤¬à¤¾à¤œà¤¾à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤­à¤¾à¤Ÿà¤¾à¤ªà¤¾à¤°à¤¾": {"canonical": "à¤¬à¤²à¥Œà¤¦à¤¾à¤¬à¤¾à¤œà¤¾à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤²à¥Œà¤¦à¤¾à¤¬à¤¾à¤œà¤¾à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤•à¤µà¤°à¥à¤§à¤¾": {"canonical": "à¤•à¤µà¤°à¥à¤§à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¤¬à¥€à¤°à¤§à¤¾à¤® à¤œà¤¿à¤²à¤¾"]},
    "à¤•à¤¾à¤‚à¤•à¥‡à¤°": {"canonical": "à¤•à¤¾à¤‚à¤•à¥‡à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¤¾à¤‚à¤•à¥‡à¤°à¤œà¤¿à¤²à¤¾"]},
    "à¤•à¥‹à¤°à¤¿à¤¯à¤¾": {"canonical": "à¤•à¥‹à¤°à¤¿à¤¯à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤°à¤¿à¤¯à¤¾à¤œà¤¿à¤²à¤¾"]},
    "à¤œà¤¶à¤ªà¥à¤°": {"canonical": "à¤œà¤¶à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤œà¤¶à¤ªà¥à¤°à¤œà¤¿à¤²à¤¾"]},
    "à¤®à¥à¤‚à¤—à¥‡à¤²à¥€": {"canonical": "à¤®à¥à¤‚à¤—à¥‡à¤²à¥€", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤®à¥à¤‚à¤—à¥‡à¤²à¥€à¤œà¤¿à¤²à¤¾"]},
    "à¤¬à¥‡à¤®à¥‡à¤¤à¤°à¤¾": {"canonical": "à¤¬à¥‡à¤®à¥‡à¤¤à¤°à¤¾", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¥‡à¤®à¥‡à¤¤à¤°à¤¾à¤œà¤¿à¤²à¤¾"]},
    "à¤—à¥Œà¤°à¥‡à¤²à¤¾": {"canonical": "à¤—à¥Œà¤°à¥‡à¤²à¤¾-à¤ªà¥‡à¤‚à¤¡à¥à¤°à¤¾-à¤®à¤°à¤µà¤¾à¤¹à¥€", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤—à¥Œà¤°à¥‡à¤²à¤¾-à¤ªà¥‡à¤‚à¤¡à¥à¤°à¤¾-à¤®à¤°à¤µà¤¾à¤¹à¥€à¤œà¤¿à¤²à¤¾"]},
    "à¤ªà¥‡à¤‚à¤¡à¥à¤°à¤¾": {"canonical": "à¤—à¥Œà¤°à¥‡à¤²à¤¾-à¤ªà¥‡à¤‚à¤¡à¥à¤°à¤¾-à¤®à¤°à¤µà¤¾à¤¹à¥€", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤—à¥Œà¤°à¥‡à¤²à¤¾-à¤ªà¥‡à¤‚à¤¡à¥à¤°à¤¾-à¤®à¤°à¤µà¤¾à¤¹à¥€à¤œà¤¿à¤²à¤¾"]},
    "à¤¸à¤¾à¤°à¤‚à¤—à¤¢à¤¼": {"canonical": "à¤¸à¤¾à¤°à¤‚à¤—à¤¢à¤¼-à¤¬à¤¿à¤²à¤¾à¤ˆà¤—à¤¢à¤¼", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¤¾à¤°à¤‚à¤—à¤¢à¤¼-à¤¬à¤¿à¤²à¤¾à¤ˆà¤—à¤¢à¤¼à¤œà¤¿à¤²à¤¾"]},
    "à¤®à¥‹à¤¹à¤²à¤¾": {"canonical": "à¤®à¥‹à¤¹à¤²à¤¾-à¤®à¤¾à¤¨à¤ªà¥à¤°", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤®à¥‹à¤¹à¤²à¤¾-à¤®à¤¾à¤¨à¤ªà¥à¤°à¤œà¤¿à¤²à¤¾"]},
    "à¤¶à¤•à¥à¤¤à¤¿": {"canonical": "à¤¶à¤•à¥à¤¤à¤¿", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¶à¤•à¥à¤¤à¤¿à¤œà¤¿à¤²à¤¾"]},
    "à¤–à¥ˆà¤°à¤¾à¤—à¤¢à¤¼": {"canonical": "à¤–à¥ˆà¤°à¤¾à¤—à¤¢à¤¼", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤–à¥ˆà¤°à¤¾à¤—à¤¢à¤¼à¤œà¤¿à¤²à¤¾"]},
    "à¤®à¤¨à¥‡à¤‚à¤¦à¥à¤°à¤—à¤¢à¤¼": {"canonical": "à¤®à¤¨à¥‡à¤‚à¤¦à¥à¤°à¤—à¤¢à¤¼", "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤®à¤¨à¥‡à¤‚à¤¦à¥à¤°à¤—à¤¢à¤¼-à¤šà¤¿à¤°à¤®à¤¿à¤°à¥€-à¤­à¤°à¤¤à¤ªà¥à¤°à¤œà¤¿à¤²à¤¾"]},
}

# -------------------------
# Utility
# -------------------------

def normalize_text_basic(text: str) -> str:
    text = re.sub(r"[â€“â€”\-_:â€œâ€\"'`]+", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip().lower()

# -------------------------
# Feature extractors
# -------------------------

def extract_schemes(text: str) -> Tuple[List[str], float]:
    schemes = set()
    for pattern, canonical in SCHEME_PATTERNS.items():
        if re.search(pattern, text, flags=re.IGNORECASE):
            schemes.add(canonical)
    if not schemes:
        return [], 0.0
    conf = min(0.95, 0.65 + 0.08 * len(schemes))
    return sorted(schemes), conf

def extract_target_groups(text: str) -> Tuple[List[str], float]:
    groups = set()
    for kw, canonical in TARGET_GROUP_KEYWORDS.items():
        if kw in text:
            groups.add(canonical)
    if not groups:
        return [], 0.0
    conf = min(0.9, 0.65 + 0.05 * len(groups))
    return sorted(groups), conf

def extract_communities(text: str) -> Tuple[List[str], float]:
    communities = set()
    for kw, canonical in COMMUNITY_KEYWORDS.items():
        if kw in text:
            communities.add(canonical)
    if not communities:
        return [], 0.0
    conf = min(0.9, 0.65 + 0.05 * len(communities))
    return sorted(communities), conf

def extract_orgs(text: str) -> Tuple[List[str], float]:
    lowered = text.lower()
    orgs = set()
    for kw, canonical in ORG_KEYWORDS.items():
        if kw.lower() in lowered:
            orgs.add(canonical)
    if not orgs:
        return [], 0.0
    conf = min(0.9, 0.65 + 0.05 * len(orgs))
    return sorted(orgs), conf

def extract_hashtags(text: str) -> List[str]:
    return re.findall(r"#(\w+)", text)

def make_word_buckets(text: str) -> Tuple[List[str], float]:
    buckets: List[str] = []

    for tag in extract_hashtags(text):
        t = tag.lower()
        if "pmawas" in t or "pmay" in t:
            buckets.append("PM à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾")
        elif "ayushman" in t:
            buckets.append("à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤")
        elif "gst" in t:
            buckets.append("GST")
        elif "kisan" in t or "farmer" in t:
            buckets.append("à¤•à¥ƒà¤·à¤¿ / à¤•à¤¿à¤¸à¤¾à¤¨")
        elif "youth" in t or "yuva" in t:
            buckets.append("à¤¯à¥à¤µà¤¾")
        elif "mahila" in t or "women" in t:
            buckets.append("à¤®à¤¹à¤¿à¤²à¤¾ à¤¸à¤¶à¤•à¥à¤¤à¤¿à¤•à¤°à¤£")

    topic_map = [
        (["à¤•à¤¿à¤¸à¤¾à¤¨", "à¤«à¤¸à¤²", "à¤–à¥‡à¤¤à¥€", "à¤•à¥ƒà¤·à¤¿"], "à¤•à¥ƒà¤·à¤¿ / à¤•à¤¿à¤¸à¤¾à¤¨"),
        (["à¤®à¤¹à¤¿à¤²à¤¾", "à¤®à¤¹à¤¿à¤²à¤¾à¤“à¤‚", "à¤¨à¤¾à¤°à¥€"], "à¤®à¤¹à¤¿à¤²à¤¾ à¤¸à¤¶à¤•à¥à¤¤à¤¿à¤•à¤°à¤£"),
        (["à¤¶à¤¿à¤•à¥à¤·à¤¾", "à¤¸à¥à¤•à¥‚à¤²", "à¤•à¥‰à¤²à¥‡à¤œ", "à¤µà¤¿à¤¦à¥à¤¯à¤¾à¤²à¤¯"], "à¤¶à¤¿à¤•à¥à¤·à¤¾"),
        (["à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯", "à¤…à¤¸à¥à¤ªà¤¤à¤¾à¤²", "à¤šà¤¿à¤•à¤¿à¤¤à¥à¤¸à¤¾", "à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤¶à¤¿à¤µà¤¿à¤°"], "à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯"),
        (["à¤¬à¤¿à¤œà¤²à¥€", "à¤°à¥‹à¤¶à¤¨à¥€", "à¤µà¤¿à¤¦à¥à¤¯à¥à¤¤"], "à¤¬à¤¿à¤œà¤²à¥€"),
        (["à¤¸à¤¡à¤¼à¤•", "à¤®à¤¾à¤°à¥à¤—", "highway", "à¤ªà¥à¤²"], "à¤¸à¤¡à¤¼à¤• / à¤‡à¤¨à¥à¤«à¥à¤°à¤¾"),
        (["à¤¨à¥Œà¤•à¤°à¥€", "à¤°à¥‹à¤œà¤¼à¤—à¤¾à¤°", "à¤°à¥‹à¤œà¤—à¤¾à¤°"], "à¤°à¥‹à¤œà¤¼à¤—à¤¾à¤°"),
        (["à¤‰à¤¦à¥à¤¯à¥‹à¤—", "à¤‰à¤¦à¥à¤¯à¥‹à¤—à¥‹à¤‚", "à¤«à¥ˆà¤•à¥à¤Ÿà¥à¤°à¥€", "industry"], "à¤‰à¤¦à¥à¤¯à¥‹à¤— / à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°"),
    ]
    lower = text.lower()
    for words, bucket in topic_map:
        if any(w.lower() in lower for w in words):
            buckets.append(bucket)

    buckets = sorted(set(buckets))
    if not buckets:
        return [], 0.0
    conf = min(0.9, 0.55 + 0.05 * len(buckets))
    return buckets, conf

# -------------------------
# Location helpers
# -------------------------

def extract_inline_location_candidates(text: str) -> List[str]:
    candidates: List[str] = []
    patterns = [
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤œà¤¿à¤²à¤¾",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¨à¤—à¤° à¤¨à¤¿à¤—à¤®",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¨à¤—à¤° à¤ªà¤¾à¤²à¤¿à¤•à¤¾",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¨à¤—à¤° à¤ªà¤‚à¤šà¤¾à¤¯à¤¤",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¤à¤¹à¤¸à¥€à¤²",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¥à¤¾à¤¨à¤¾",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤µà¤¿à¤•à¤¾à¤¸à¤–à¤‚à¤¡",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤šà¥Œà¤•à¥€",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤—à¥à¤°à¤¾à¤® à¤ªà¤‚à¤šà¤¾à¤¯à¤¤",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤—à¥à¤°à¤¾à¤®",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤—à¤¾à¤à¤µ",
    ]
    for pat in patterns:
        for m in re.finditer(pat, text):
            name = m.group(1).strip()
            if len(name) >= 2:
                candidates.append(name)
    return candidates

def normalize_location(text: str, hint_location: Optional[Dict[str, Any]]) -> Tuple[Optional[Dict[str, Any]], float]:
    candidates: List[str] = []
    if hint_location:
        can = hint_location.get("canonical") or hint_location.get("district")
        if can:
            candidates.append(str(can))

    for key in CANONICAL_LOCATIONS.keys():
        if key in text or key.lower() in text.lower():
            candidates.append(key)

    candidates.extend(extract_inline_location_candidates(text))

    if not candidates:
        return None, 0.0

    best_raw, _ = Counter(candidates).most_common(1)[0]
    loc_info = CANONICAL_LOCATIONS.get(best_raw)

    if not loc_info:
        loc_obj = {
            "district": None,
            "assembly": None,
            "block": None,
            "gp": None,
            "village": None,
            "ulb": None,
            "zone": None,
            "ward": None,
            "canonical_key": None,
            "canonical": best_raw,
            "aliases": [best_raw],
            "hierarchy_path": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼"],
            "visit_count": 1,
        }
        return loc_obj, 0.55

    canonical = loc_info["canonical"]
    hierarchy = loc_info.get("hierarchy", [])
    district = None
    assembly = None
    for level in hierarchy:
        if "à¤œà¤¿à¤²à¤¾" in level:
            district = level.replace(" à¤œà¤¿à¤²à¤¾", "")
        if "à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾" in level:
            assembly = level.replace(" à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾", "")

    loc_obj = {
        "district": district,
        "assembly": assembly,
        "block": None,
        "gp": None,
        "village": None,
        "ulb": None,
        "zone": None,
        "ward": None,
        "canonical_key": f"CG_{canonical}",
        "canonical": canonical,
        "aliases": [best_raw] if best_raw not in [canonical] else [canonical],
        "hierarchy_path": hierarchy,
        "visit_count": 1,
    }
    return loc_obj, 0.88

# -------------------------
# Event inference
# -------------------------

def infer_event_from_keywords(text: str) -> Tuple[str, float]:
    text_l = text.lower()
    candidate = None
    best = 0.0
    for keywords, label in EVENT_KEYWORD_CLUSTERS:
        if any(kw.lower() in text_l for kw in keywords):
            base = 0.70
            if label in [
                "à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶",
                "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾",
                "à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤¨à¤¿à¤• à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•",
                "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸",
                "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ",
                "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾",
            ]:
                base = 0.80
            if base > best:
                best = base
                candidate = label
    if candidate is None:
        candidate = "à¤…à¤¨à¥à¤¯"
        best = 0.30
    return candidate, best

def combine_event_signals(
    hint_event_v5: Optional[str],
    keyword_event: str,
    keyword_conf: float,
    rescue_event: Optional[str],
) -> Tuple[str, float, Dict[str, Any]]:
    meta: Dict[str, Any] = {
        "source_keyword": keyword_event,
        "source_hint_v5": hint_event_v5,
        "source_rescue": rescue_event,
        "agreement_score": 0.0,
    }

    def norm(e: Optional[str]) -> Optional[str]:
        if e is None:
            return None
        e = e.strip()
        if e not in ALLOWED_EVENT_TYPES_HI:
            return None
        return e

    hint = norm(hint_event_v5)
    resc = norm(rescue_event)
    kw = norm(keyword_event) or "à¤…à¤¨à¥à¤¯"

    if hint and kw == hint and kw != "à¤…à¤¨à¥à¤¯":
        chosen = kw
        agreement = 1.0
    elif resc and kw == resc and kw != "à¤…à¤¨à¥à¤¯":
        chosen = kw
        agreement = 1.0
    elif resc and resc != "à¤…à¤¨à¥à¤¯":
        chosen = resc
        agreement = 0.8
    elif hint and hint != "à¤…à¤¨à¥à¤¯":
        chosen = hint
        agreement = 0.7
    else:
        chosen = kw
        agreement = 0.5 if kw != "à¤…à¤¨à¥à¤¯" else 0.2

    base = keyword_conf
    if chosen != "à¤…à¤¨à¥à¤¯":
        if agreement >= 1.0:
            base = max(base, 0.82)
        elif agreement >= 0.8:
            base = max(base, 0.78)
        elif agreement >= 0.7:
            base = max(base, 0.72)
        else:
            base = max(base, 0.65)
    else:
        base = min(base, 0.45)

    meta["agreement_score"] = agreement
    return chosen, round(base, 3), meta

# -------------------------
# Rescue detectors (ordered)
# -------------------------

def _looks_like_sports_tweet(text_l: str) -> bool:
    sports_specific = ["à¤•à¥à¤°à¤¿à¤•à¥‡à¤Ÿ", "à¤Ÿà¥€à¤® à¤‡à¤‚à¤¡à¤¿à¤¯à¤¾", "world cup", "à¤µà¤°à¥à¤²à¥à¤¡ à¤•à¤ª", "t20", "à¤Ÿà¥€20", "ipl", "odi", "à¤µà¤¨à¤¡à¥‡", "bcci", "à¤°à¤£à¤œà¥€"]
    if any(kw in text_l for kw in sports_specific):
        return True
    if "à¤®à¥ˆà¤š" in text_l and any(kw in text_l for kw in ["à¤œà¥€à¤¤", "à¤¹à¤¾à¤°", "à¤µà¤¿à¤•à¥‡à¤Ÿ", "à¤°à¤¨", "won", "lost"]):
        return True
    return False

def _looks_like_sports_achievement(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤¸à¥à¤µà¤°à¥à¤£ à¤ªà¤¦à¤•", "à¤°à¤œà¤¤ à¤ªà¤¦à¤•", "à¤•à¤¾à¤‚à¤¸à¥à¤¯ à¤ªà¤¦à¤•", "medal", "championship"])

def _looks_like_security_context(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤®à¤¾à¤“à¤µà¤¾à¤¦à¥€", "à¤®à¤¾à¤“à¤µà¤¾à¤¦", "à¤¨à¤•à¥à¤¸à¤²", "à¤¨à¤•à¥à¤¸à¤²à¥€", "à¤†à¤¤à¤‚à¤•", "à¤‰à¤—à¥à¤°à¤µà¤¾à¤¦", "à¤¶à¤¹à¥€à¤¦", "jawan", "encounter"])

def _looks_like_administrative_update(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤¬à¥ˆà¤ à¤•", "à¤¸à¤®à¥€à¤•à¥à¤·à¤¾", "à¤•à¤²à¥‡à¤•à¥à¤Ÿà¤°", "à¤¨à¤¿à¤°à¥à¤¦à¥‡à¤¶", "à¤…à¤§à¤¿à¤•à¤¾à¤°à¥€", "progress", "status", "à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£"])

def _looks_like_scheme_implementation(text_l: str, schemes: List[str]) -> bool:
    return bool(schemes) or any(kw in text_l for kw in ["à¤²à¤¾à¤­à¤¾à¤°à¥à¤¥à¥€", "à¤µà¤¿à¤¤à¤°à¤£", "à¤–à¤¾à¤¤à¤¾", "subsidy", "dbt", "installments"])

def _looks_like_election_politics(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤šà¥à¤¨à¤¾à¤µ", "à¤®à¤¤à¤¦à¤¾à¤¨", "à¤µà¥‹à¤Ÿ", "à¤ªà¥à¤°à¤šà¤¾à¤°", "à¤•à¥ˆà¤‚à¤ªà¥‡à¤¨", "à¤ªà¥à¤°à¤¤à¥à¤¯à¤¾à¤¶à¥€", "nomination", "polling", "à¤°à¥ˆà¤²à¥€"])

def _looks_like_industrial_development(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤‰à¤¦à¥à¤¯à¥‹à¤—", "à¤¨à¤¿à¤µà¥‡à¤¶", "à¤«à¥ˆà¤•à¥à¤Ÿà¥à¤°à¥€", "à¤°à¥‹à¤œà¤—à¤¾à¤°", "infotech", "industrial", "mou"])

def _looks_like_infrastructure_work(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤¸à¤¡à¤¼à¤•", "à¤ªà¥à¤²", "à¤­à¤µà¤¨", "à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£", "construction", "bridge", "highway"])

def _looks_like_relief_humanitarian(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤°à¤¾à¤¹à¤¤", "à¤†à¤ªà¤¦à¤¾", "à¤¬à¤¾à¤¢à¤¼", "à¤®à¥à¤†à¤µà¤œà¤¾", "à¤•à¥à¤·à¤¤à¤¿à¤ªà¥‚à¤°à¥à¤¤à¤¿", "à¤¹à¤¾à¤¦à¤¸à¤¾", "à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾"])

def _looks_like_general_political(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤¡à¤¬à¤² à¤‡à¤‚à¤œà¤¨", "à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸", "à¤­à¤¾à¤œà¤ªà¤¾", "à¤µà¤¿à¤ªà¤•à¥à¤·", "à¤¤à¥à¤·à¥à¤Ÿà¤¿à¤•à¤°à¤£", "à¤­à¥à¤°à¤·à¥à¤Ÿà¤¾à¤šà¤¾à¤°", "à¤†à¤°à¥‹à¤ª"])

def _looks_like_policy_statement(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤µà¤¿à¤•à¤¸à¤¿à¤¤ à¤­à¤¾à¤°à¤¤", "à¤®à¥‹à¤¦à¥€ à¤•à¥€ à¤—à¤¾à¤°à¤‚à¤Ÿà¥€", "à¤¸à¤¬à¤•à¤¾ à¤¸à¤¾à¤¥", "à¤¸à¤‚à¤•à¤²à¥à¤ª"])

def _looks_like_cultural_religious(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤®à¤‚à¤¦à¤¿à¤°", "à¤ªà¥‚à¤œà¤¾", "à¤¦à¤°à¥à¤¶à¤¨", "à¤œà¤¯à¤‚à¤¤à¥€", "à¤®à¤¹à¥‹à¤¤à¥à¤¸à¤µ", "à¤ªà¤°à¥à¤µ", "arti"])

def _looks_like_congratulatory_general(text_l: str) -> bool:
    return any(kw in text_l for kw in ["à¤¬à¤§à¤¾à¤ˆ", "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾", "best wishes", "greetings", "à¤®à¥à¤¬à¤¾à¤°à¤•"])

def _looks_like_digital_only(text_l: str, loc_obj: Optional[Dict[str, Any]]) -> bool:
    digital_kw = ["online", "à¤‘à¤¨à¤²à¤¾à¤‡à¤¨", "live", "à¤²à¤¾à¤‡à¤µ", "à¤œà¥à¤¡à¤¼à¥‡à¤‚", "link", "à¤²à¤¿à¤‚à¤•", "stream"]
    no_loc = not (loc_obj and loc_obj.get("canonical"))
    return no_loc and any(kw in text_l for kw in digital_kw)

def rescue_other_events_OpenAI_V1(text: str, base_pd: Dict[str, Any]) -> Dict[str, Any]:
    text_l = normalize_text_basic(text)
    original_event = base_pd.get("event_type") or "à¤…à¤¨à¥à¤¯"
    loc_obj = base_pd.get("location")
    schemes = base_pd.get("schemes_mentioned") or []

    pd_extra: Dict[str, Any] = {
        "event_type_rescue": None,
        "content_mode": None,
        "is_other_original": (original_event == "à¤…à¤¨à¥à¤¯"),
        "is_rescued_other": False,
        "rescue_tag": None,
        "rescue_confidence_bonus": 0.0,
    }

    # 0. If original non-"à¤…à¤¨à¥à¤¯": à¤¸à¤¿à¤°à¥à¤« content_mode refine à¤•à¤°à¥‡à¤‚à¤—à¥‡
    if original_event != "à¤…à¤¨à¥à¤¯":
        if _looks_like_digital_only(text_l, loc_obj):
            pd_extra["content_mode"] = "à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² / à¤¸à¥‹à¤¶à¤²-à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤ªà¥‹à¤¸à¥à¤Ÿ"
        return pd_extra

    # --- Priority 1: High-specific categories ---
    if _looks_like_sports_tweet(text_l) or _looks_like_sports_achievement(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ",
            "content_mode": "à¤–à¥‡à¤² / à¤‰à¤ªà¤²à¤¬à¥à¤§à¤¿ à¤ªà¤° à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾",
            "is_rescued_other": True,
            "rescue_tag": "sports_OpenAI_V1",
            "rescue_confidence_bonus": 0.06,
        })
        return pd_extra

    if _looks_like_security_context(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸",
            "content_mode": "à¤¨à¥€à¤¤à¤¿ / à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
            "is_rescued_other": True,
            "rescue_tag": "security_OpenAI_V1",
            "rescue_confidence_bonus": 0.07,
        })
        return pd_extra

    # --- Priority 2: Governance ---
    if _looks_like_administrative_update(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤¨à¤¿à¤• à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•",
            "content_mode": "à¤¨à¥€à¤¤à¤¿ / à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
            "is_rescued_other": True,
            "rescue_tag": "admin_OpenAI_V1",
            "rescue_confidence_bonus": 0.06,
        })
        return pd_extra

    if _looks_like_election_politics(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤šà¥à¤¨à¤¾à¤µ à¤ªà¥à¤°à¤šà¤¾à¤°",
            "content_mode": "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
            "is_rescued_other": True,
            "rescue_tag": "election_OpenAI_V1",
            "rescue_confidence_bonus": 0.06,
        })
        return pd_extra

    # --- Priority 3: Development & Schemes ---
    if _looks_like_industrial_development(text_l) or _looks_like_infrastructure_work(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤‰à¤¦à¥à¤˜à¤¾à¤Ÿà¤¨",
            "content_mode": "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
            "is_rescued_other": True,
            "rescue_tag": "infra_dev_OpenAI_V1",
            "rescue_confidence_bonus": 0.06,
        })
        return pd_extra

    if _looks_like_scheme_implementation(text_l, schemes) or _looks_like_relief_humanitarian(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤¯à¥‹à¤œà¤¨à¤¾ à¤˜à¥‹à¤·à¤£à¤¾",
            "content_mode": "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
            "is_rescued_other": True,
            "rescue_tag": "scheme_OpenAI_V1",
            "rescue_confidence_bonus": 0.06,
        })
        return pd_extra

    # --- Priority 4: Political / Cultural / Greetings ---
    if _looks_like_general_political(text_l) or _looks_like_policy_statement(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
            "content_mode": "à¤¨à¥€à¤¤à¤¿ / à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
            "is_rescued_other": True,
            "rescue_tag": "political_OpenAI_V1",
            "rescue_confidence_bonus": 0.05,
        })
        return pd_extra

    if _looks_like_cultural_religious(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤§à¤¾à¤°à¥à¤®à¤¿à¤• / à¤¸à¤¾à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤• à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
            "content_mode": "à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤ / à¤ªà¤°à¥à¤µ",
            "is_rescued_other": True,
            "rescue_tag": "cultural_OpenAI_V1",
            "rescue_confidence_bonus": 0.05,
        })
        return pd_extra

    if _looks_like_congratulatory_general(text_l):
        pd_extra.update({
            "event_type_rescue": "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾ / à¤¬à¤§à¤¾à¤ˆ",
            "content_mode": "à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤ / à¤ªà¤°à¥à¤µ",
            "is_rescued_other": True,
            "rescue_tag": "greetings_OpenAI_V1",
            "rescue_confidence_bonus": 0.04,
        })
        return pd_extra

    # --- Fallback: digital-mode only ---
    if _looks_like_digital_only(text_l, loc_obj):
        pd_extra.update({
            "content_mode": "à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² / à¤¸à¥‹à¤¶à¤²-à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤ªà¥‹à¤¸à¥à¤Ÿ",
            "rescue_tag": "digital_mode_OpenAI_V1",
            "rescue_confidence_bonus": 0.02,
        })
        return pd_extra

    pd_extra["content_mode"] = "à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² / à¤¸à¥‹à¤¶à¤²-à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤ªà¥‹à¤¸à¥à¤Ÿ"
    return pd_extra

# -------------------------
# Confidence & review
# -------------------------

def compute_confidence_OpenAI_V1(
    c_event_final: float,
    c_loc: float,
    c_schemes: float,
    c_topics: float,
    c_targets: float,
    c_comm: float,
    c_org: float,
    event_type: str,
    location_obj: Optional[Dict[str, Any]],
    people: List[Any],
    agreement_score: float,
    rescue_bonus: float,
    text_len: int,
) -> float:
    good_event = event_type != "à¤…à¤¨à¥à¤¯"
    has_loc = bool(location_obj and location_obj.get("canonical"))
    has_people = bool(people)
    has_groups = c_targets > 0 or c_comm > 0
    has_schemes = c_schemes > 0
    has_topics = c_topics > 0
    has_org = c_org > 0

    base = 0.2
    if good_event:
        base += 0.25
    if has_loc:
        base += 0.2
    if has_schemes:
        base += 0.05
    if has_topics:
        base += 0.05
    if has_groups:
        base += 0.05
    if has_org:
        base += 0.03

    weighted = (
        2 * c_event_final
        + 2 * c_loc
        + c_schemes
        + c_topics
        + c_targets
        + c_comm
        + c_org
    ) / 9.0

    score = max(base, (base * 0.7 + weighted * 0.3))
    score += 0.05 * (agreement_score - 0.5)

    if good_event and has_loc and has_people:
        score += 0.05
    elif good_event and (has_loc or has_people):
        score += 0.02

    score += rescue_bonus

    HIGH_PRECISION = ["à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶", "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾", "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸", "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ", "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾"]
    substantial = text_len > 20

    if event_type in HIGH_PRECISION and substantial and good_event and (has_loc or has_people or has_schemes):
        score = max(score, 0.92)

    if text_len <= 20:
        score = min(score, 0.88)

    return round(min(0.99, max(0.0, score)), 3)

def decide_review_status(conf: float) -> Tuple[str, bool]:
    if conf >= 0.90:
        return "auto_approved", False
    if conf >= 0.75:
        return "pending", False
    return "pending", True

# -------------------------
# Main parsing
# -------------------------

def parse_tweet_OpenAI_V1(record: Dict[str, Any]) -> Dict[str, Any]:
    text = record.get("raw_text") or record.get("text") or ""
    created_at = record.get("created_at")
    old_v5 = record.get("parsed_data_v5") or {}
    old_v6 = record.get("parsed_data_v6") or {}
    hint_event_v5 = old_v6.get("event_type") or old_v5.get("event_type")

    schemes, c_schemes = extract_schemes(text)
    word_buckets, c_topics = make_word_buckets(text)
    target_groups, c_targets = extract_target_groups(text)
    communities, c_comm = extract_communities(text)
    orgs, c_org = extract_orgs(text)

    people_mentioned = old_v5.get("people_mentioned", []) or old_v6.get("people_mentioned", [])

    hint_loc = old_v6.get("location") or old_v5.get("location")
    loc_obj, c_loc = normalize_location(text, hint_loc)

    kw_event, c_kw = infer_event_from_keywords(text)
    base_pd_for_rescue = {
        "event_type": kw_event,
        "location": loc_obj,
        "schemes_mentioned": schemes,
    }
    rescue_info = rescue_other_events_OpenAI_V1(text, base_pd_for_rescue)
    rescue_event = rescue_info.get("event_type_rescue")

    event_type_final, c_event_final, event_meta = combine_event_signals(
        hint_event_v5=hint_event_v5,
        keyword_event=kw_event,
        keyword_conf=c_kw,
        rescue_event=rescue_event,
    )

    content_mode = rescue_info.get("content_mode")
    if not content_mode:
        if loc_obj and loc_obj.get("canonical"):
            content_mode = "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®"
        else:
            content_mode = "à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² / à¤¸à¥‹à¤¶à¤²-à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤ªà¥‹à¤¸à¥à¤Ÿ"

    rescue_bonus = rescue_info.get("rescue_confidence_bonus", 0.0)
    is_rescued_other = bool(rescue_info.get("is_rescued_other") and event_type_final != "à¤…à¤¨à¥à¤¯")

    conf = compute_confidence_OpenAI_V1(
        c_event_final=c_event_final,
        c_loc=c_loc,
        c_schemes=c_schemes,
        c_topics=c_topics,
        c_targets=c_targets,
        c_comm=c_comm,
        c_org=c_org,
        event_type=event_type_final,
        location_obj=loc_obj,
        people=people_mentioned or [],
        agreement_score=event_meta.get("agreement_score", 0.5),
        rescue_bonus=rescue_bonus,
        text_len=len(text),
    )

    review_status, needs_review = decide_review_status(conf)

    parsed_data_OpenAI_V1 = {
        "event_type": event_type_final,
        "event_type_secondary": [],
        "event_date": created_at[:10] if created_at else None,
        "location": loc_obj,
        "people_mentioned": people_mentioned or [],
        "schemes_mentioned": schemes,
        "word_buckets": word_buckets,
        "target_groups": target_groups,
        "communities": communities,
        "organizations": orgs,
        "hierarchy_path": (loc_obj or {}).get("hierarchy_path", []),
        "visit_count": (loc_obj or {}).get("visit_count", 0),
        "confidence": conf,
        "review_status": review_status,
        "needs_review": needs_review,
        "content_mode": content_mode,
        "is_other_original": (kw_event == "à¤…à¤¨à¥à¤¯"),
        "is_rescued_other": is_rescued_other,
        "rescue_tag": rescue_info.get("rescue_tag"),
        "source_hint_event": hint_event_v5,
        "source_keyword_event": kw_event,
        "source_rescue_event": rescue_event,
        "agreement_score": event_meta.get("agreement_score", 0.5),
    }

    return {
        "tweet_id": record.get("tweet_id"),
        "created_at": created_at,
        "raw_text": text,
        "parsed_data_v5": old_v5,
        "parsed_data_v6": old_v6,
        "parsed_data_OpenAI_V1": parsed_data_OpenAI_V1,
        "metadata_OpenAI_V1": {"model": "OpenAI_V1-rule-engine-consensus-think-harder"},
    }

def reparse_file_OpenAI_V1(input_path: Path, output_path: Path) -> None:
    print(f"ðŸš€ OpenAI_V1 Parsing à¤¶à¥à¤°à¥‚: {input_path} â†’ {output_path}")
    total = 0
    stats = Counter()

    with input_path.open("r", encoding="utf-8") as fin, output_path.open("w", encoding="utf-8") as fout:
        for line in fin:
            line = line.strip()
            if not line:
                continue
            try:
                rec = json.loads(line)
            except Exception:
                continue

            total += 1
            new_rec = parse_tweet_OpenAI_V1(rec)
            pd = new_rec["parsed_data_OpenAI_V1"]

            c = pd["confidence"]
            if c >= 0.90:
                stats["High (>=0.90)"] += 1
            elif c >= 0.70:
                stats["Medium (0.70-0.90)"] += 1
            else:
                stats["Low (<0.70)"] += 1

            if pd["event_type"] == "à¤…à¤¨à¥à¤¯":
                stats["Event: à¤…à¤¨à¥à¤¯"] += 1
            else:
                stats[f"Event: {pd['event_type']}"] += 1

            if pd["is_rescued_other"]:
                stats["Rescued Others"] += 1

            fout.write(json.dumps(new_rec, ensure_ascii=False) + "\n")

    print(f"\nâœ… OpenAI_V1 Complete. Total tweets: {total}")
    print(f"   High  (>=0.90): {stats['High (>=0.90)']}")
    print(f"   Medium(0.70-0.90): {stats['Medium (0.70-0.90)']}")
    print(f"   Low   (<0.70): {stats['Low (<0.70)']}")
    print(f"   Rescued Others: {stats['Rescued Others']}")
    print("\n   Event distribution (top 20):")
    for k, v in list(stats.most_common(30)):
        if k.startswith("Event:"):
            print(f"     {k}: {v}")

if __name__ == "__main__":
    inp = Path(sys.argv[1]) if len(sys.argv) > 1 else DEFAULT_INPUT
    out = Path(sys.argv[2]) if len(sys.argv) > 2 else DEFAULT_OUTPUT
    reparse_file_OpenAI_V1(inp, out)
