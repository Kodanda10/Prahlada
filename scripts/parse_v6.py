#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Project Dhruv â€“ Parsing Logic V6.0 (High-Confidence, Expanded Taxonomy)

V6.0 Updates:
- âœ… New Categories: Internal Security, Sports/Pride, Political Statement, Disaster/Accident.
- âœ… Signal Multiplier: Confidence boosted >0.90 for high-precision matches.
- âœ… Triangulation Bonus: (Event + Location + Person) = Confidence >0.95.
- âœ… Refined Rescue: Maps vague tweets to specific new categories.

Taxonomy (19 categories):
- Added: à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸, à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ, à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤µà¤•à¥à¤¤à¤µà¥à¤¯, à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾

Usage:
  python3 parse_v6.py input.jsonl output.jsonl
"""

import json
import re
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from collections import Counter

# -------------------------
# Paths
# -------------------------

DEFAULT_INPUT = Path(__file__).parent.parent / "data" / "parsed_tweets_v5.jsonl"
DEFAULT_OUTPUT = Path(__file__).parent.parent / "data" / "parsed_tweets_v6.jsonl"

# -------------------------
# Taxonomies / Enums
# -------------------------

ALLOWED_EVENT_TYPES_HI = [
    "à¤¬à¥ˆà¤ à¤•",
    "à¤œà¤¨à¤¸à¤®à¥à¤ªà¤°à¥à¤• / à¤œà¤¨à¤¦à¤°à¥à¤¶à¤¨",
    "à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤¨à¤¿à¤• à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•",
    "à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£",
    "à¤°à¥ˆà¤²à¥€",
    "à¤šà¥à¤¨à¤¾à¤µ à¤ªà¥à¤°à¤šà¤¾à¤°",
    "à¤‰à¤¦à¥à¤˜à¤¾à¤Ÿà¤¨",
    "à¤¯à¥‹à¤œà¤¨à¤¾ à¤˜à¥‹à¤·à¤£à¤¾",
    "à¤§à¤¾à¤°à¥à¤®à¤¿à¤• / à¤¸à¤¾à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤• à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
    "à¤¸à¤®à¥à¤®à¤¾à¤¨ / Felicitation",
    "à¤ªà¥à¤°à¥‡à¤¸ à¤•à¥‰à¤¨à¥à¤«à¤¼à¥à¤°à¥‡à¤‚à¤¸ / à¤®à¥€à¤¡à¤¿à¤¯à¤¾",
    "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾ / à¤¬à¤§à¤¾à¤ˆ",
    "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾",
    "à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶",
    # --- NEW V6 CATEGORIES ---
    "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸",
    "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ",
    "à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
    "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾",
    # -------------------------
    "à¤…à¤¨à¥à¤¯",
]

CONTENT_MODES = [
    "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
    "à¤¨à¥€à¤¤à¤¿ / à¤µà¤•à¥à¤¤à¤µà¥à¤¯",
    "à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² / à¤¸à¥‹à¤¶à¤²-à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤ªà¥‹à¤¸à¥à¤Ÿ",
    "à¤–à¥‡à¤² / à¤‰à¤ªà¤²à¤¬à¥à¤§à¤¿ à¤ªà¤° à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾",
    "à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤ / à¤ªà¤°à¥à¤µ",
]

# keyword clusters â†’ Hindi label (base event detection)
EVENT_KEYWORD_CLUSTERS: List[Tuple[List[str], str]] = [
    # 1. V6 NEW: Internal Security / Police
    (["à¤®à¤¾à¤“à¤µà¤¾à¤¦", "à¤¨à¤•à¥à¤¸à¤²", "à¤¨à¤•à¥à¤¸à¤²à¥€", "à¤²à¤¾à¤² à¤†à¤¤à¤‚à¤•", "à¤¸à¥à¤°à¤•à¥à¤·à¤¾ à¤¬à¤²", "à¤œà¤µà¤¾à¤¨à¥‹à¤‚", "à¤¶à¤¹à¥€à¤¦", 
      "à¤†à¤¤à¥à¤®à¤¸à¤®à¤°à¥à¤ªà¤£", "à¤¬à¤¸à¥à¤¤à¤° à¤“à¤²à¤‚à¤ªà¤¿à¤•", "à¤‘à¤ªà¤°à¥‡à¤¶à¤¨", "à¤ªà¥à¤²à¤¿à¤¸ à¤¸à¥à¤®à¥ƒà¤¤à¤¿", "police", "jawan"], "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸"),

    # 2. V6 NEW: Sports / Pride
    (["à¤®à¥ˆà¤š à¤œà¥€à¤¤", "à¤Ÿà¥€à¤® à¤‡à¤‚à¤¡à¤¿à¤¯à¤¾", "à¤•à¥à¤°à¤¿à¤•à¥‡à¤Ÿ", "à¤ªà¤¦à¤•", "à¤¸à¥à¤µà¤°à¥à¤£ à¤ªà¤¦à¤•", "à¤–à¤¿à¤²à¤¾à¤¡à¤¼à¥€", 
      "à¤“à¤²à¤‚à¤ªà¤¿à¤•", "à¤–à¥‡à¤²", "tournament", "à¤šà¥ˆà¤‚à¤ªà¤¿à¤¯à¤‚à¤¸ à¤Ÿà¥à¤°à¥‰à¤«à¥€", "à¤—à¤°à¥à¤µ à¤•à¤¾ à¤•à¥à¤·à¤£", "medal", "won", "winner"], "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ"),

    # 3. V6 NEW: Disaster / Accident
    (["à¤¹à¤¾à¤¦à¤¸à¤¾", "à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾", "à¤°à¥‡à¤² à¤¹à¤¾à¤¦à¤¸à¤¾", "à¤¬à¤¸ à¤¹à¤¾à¤¦à¤¸à¤¾", "à¤†à¤—à¤œà¤¨à¥€", "à¤¬à¤¾à¤¢à¤¼", "à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤• à¤†à¤ªà¤¦à¤¾", "accident", "tragedy"], "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾"),

    # 4. V6 NEW: Political Statement
    (["à¤¡à¤¬à¤² à¤‡à¤‚à¤œà¤¨", "à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸ à¤¸à¤°à¤•à¤¾à¤°", "à¤­à¥à¤°à¤·à¥à¤Ÿà¤¾à¤šà¤¾à¤°", "à¤¤à¥à¤·à¥à¤Ÿà¤¿à¤•à¤°à¤£", "à¤†à¤ªà¤¾à¤¤à¤•à¤¾à¤²", 
      "à¤µà¤¿à¤•à¤¸à¤¿à¤¤ à¤­à¤¾à¤°à¤¤", "à¤®à¥‹à¤¦à¥€ à¤•à¥€ à¤—à¤¾à¤°à¤‚à¤Ÿà¥€", "à¤µà¤¿à¤ªà¤•à¥à¤·", "à¤†à¤°à¥‹à¤ª", "statement", "political"], "à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤µà¤•à¥à¤¤à¤µà¥à¤¯"),

    # --- Existing Categories ---
    (["à¤¬à¥ˆà¤ à¤•", "à¤®à¥à¤²à¤¾à¤•à¤¾à¤¤", "à¤­à¥‡à¤‚à¤Ÿ", "à¤¬à¥ˆà¤ à¤• à¤²à¥€", "à¤¬à¥ˆà¤ à¤• à¤®à¥‡à¤‚", "à¤¬à¥ˆà¤ à¤• à¤•à¤¾", "à¤…à¤§à¥à¤¯à¤•à¥à¤·à¤¤à¤¾ à¤•à¥€", "à¤¸à¤¤à¥à¤°", "à¤¸à¤¦à¤¨ à¤•à¥€ à¤•à¤¾à¤°à¥à¤¯à¤µà¤¾à¤¹à¥€"], "à¤¬à¥ˆà¤ à¤•"),
    (["à¤œà¤¨à¤¸à¤®à¥à¤ªà¤°à¥à¤•", "à¤œà¤¨ à¤¸à¤‚à¤ªà¤°à¥à¤•", "à¤œà¤¨à¤¸à¤‚à¤ªà¤°à¥à¤•", "à¤œà¤¨à¤¦à¤°à¥à¤¶à¤¨", "à¤œà¤¨-à¤¦à¤°à¥à¤¶à¤¨", "à¤œà¤¨ à¤¸à¥à¤¨à¤µà¤¾à¤ˆ", "à¤œà¤¨à¤¸à¥à¤¨à¤µà¤¾à¤ˆ"], "à¤œà¤¨à¤¸à¤®à¥à¤ªà¤°à¥à¤• / à¤œà¤¨à¤¦à¤°à¥à¤¶à¤¨"),
    (["à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•", "à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤•à¥€", "à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤•à¥€ à¤—à¤ˆ", "à¤…à¤§à¤¿à¤•à¤¾à¤°à¤¿à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¸à¤¾à¤¥", "à¤µà¤¿à¤­à¤¾à¤—à¥€à¤¯ à¤¬à¥ˆà¤ à¤•", "à¤•à¤²à¥‡à¤•à¥à¤Ÿà¤°", "à¤•à¤²à¥‡à¤•à¥à¤Ÿà¤°à¥‡à¤Ÿ", "à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤•à¤¾à¤°à¥à¤¯"], "à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤¨à¤¿à¤• à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•"),
    (["à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£", "à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£ à¤•à¤¿à¤¯à¤¾", "à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£ à¤¹à¥‡à¤¤à¥", "inspection"], "à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£"),
    (["à¤°à¥ˆà¤²à¥€", "à¤œà¤¨à¤¸à¤­à¤¾", "public rally", "road show", "à¤°à¥‹à¤¡ à¤¶à¥‹"], "à¤°à¥ˆà¤²à¥€"),
    (["à¤šà¥à¤¨à¤¾à¤µà¥€", "à¤®à¤¤à¤¦à¤¾à¤¤à¤¾", "à¤®à¤¤à¤¦à¤¾à¤¨", "à¤šà¥à¤¨à¤¾à¤µ à¤ªà¥à¤°à¤šà¤¾à¤°", "poll campaign"], "à¤šà¥à¤¨à¤¾à¤µ à¤ªà¥à¤°à¤šà¤¾à¤°"),
    (["à¤‰à¤¦à¥à¤˜à¤¾à¤Ÿà¤¨", "à¤²à¥‹à¤•à¤¾à¤°à¥à¤ªà¤£", "inauguration", "inaugurated", "à¤¶à¤¿à¤²à¤¾à¤¨à¥à¤¯à¤¾à¤¸"], "à¤‰à¤¦à¥à¤˜à¤¾à¤Ÿà¤¨"),
    (["à¤˜à¥‹à¤·à¤£à¤¾", "à¤¨à¤ˆ à¤¯à¥‹à¤œà¤¨à¤¾", "à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€", "à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¤¾ à¤²à¤¾à¤­"], "à¤¯à¥‹à¤œà¤¨à¤¾ à¤˜à¥‹à¤·à¤£à¤¾"),
    (["à¤®à¤‚à¤¦à¤¿à¤°", "à¤ªà¥‚à¤œà¤¾", "à¤†à¤°à¤¤à¥€", "à¤—à¥à¤°à¥à¤¦à¥à¤µà¤¾à¤°à¤¾", "à¤—à¥à¤°à¥ à¤¨à¤¾à¤¨à¤•", "à¤®à¤¸à¥à¤œà¤¿à¤¦", "à¤§à¤¾à¤°à¥à¤®à¤¿à¤•", "à¤¸à¤¾à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤• à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®", "à¤œà¤¯à¤‚à¤¤à¥€"], "à¤§à¤¾à¤°à¥à¤®à¤¿à¤• / à¤¸à¤¾à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤• à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®"),
    (["à¤¸à¤®à¥à¤®à¤¾à¤¨", "à¤¸à¤®à¥à¤®à¤¾à¤¨à¤¿à¤¤", "à¤¶à¥‰à¤²", "à¤¶à¥à¤°à¥€à¤«à¤²", "à¤¸à¤®à¤¾à¤°à¥‹à¤¹", "felicitation"], "à¤¸à¤®à¥à¤®à¤¾à¤¨ / Felicitation"),
    (["à¤ªà¥à¤°à¥‡à¤¸ à¤µà¤¾à¤°à¥à¤¤à¤¾", "à¤ªà¥à¤°à¥‡à¤¸ à¤•à¥‰à¤¨à¥à¤«à¤¼à¥à¤°à¥‡à¤‚à¤¸", "à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤¬à¥à¤°à¤¿à¤«à¤¿à¤‚à¤—", "à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤¸à¥‡ à¤¬à¤¾à¤¤à¤šà¥€à¤¤"], "à¤ªà¥à¤°à¥‡à¤¸ à¤•à¥‰à¤¨à¥à¤«à¤¼à¥à¤°à¥‡à¤‚à¤¸ / à¤®à¥€à¤¡à¤¿à¤¯à¤¾"),
    (["à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤‚", "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤", "à¤¬à¤§à¤¾à¤ˆ", "congratulations"], "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾ / à¤¬à¤§à¤¾à¤ˆ"),
    (["à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨", "birthday"], "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾"),
    (["à¤¶à¥à¤°à¤¦à¥à¤§à¤¾à¤‚à¤œà¤²à¤¿", "à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶", "à¤¦à¤¿à¤µà¤‚à¤—à¤¤", "à¤…à¤‚à¤¤à¤¿à¤® à¤¯à¤¾à¤¤à¥à¤°à¤¾", "à¤ªà¥à¤£à¥à¤¯à¤¤à¤¿à¤¥à¤¿", "condolence"], "à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶"),
]

SCHEME_PATTERNS = {
    r"\bPMAY\b": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤ªà¥à¤°à¤§à¤¾à¤¨ à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"PM Awas": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤": "à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤",
    r"\bAyushman\b": "à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤",
    r"Ayushman Bharat": "à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤",
    r"à¤‰à¤œà¥à¤œà¥à¤µà¤²à¤¾ à¤¯à¥‹à¤œà¤¨à¤¾": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤‰à¤œà¥à¤œà¥à¤µà¤²à¤¾ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"\bUjjwala\b": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤‰à¤œà¥à¤œà¥à¤µà¤²à¤¾ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"à¤¸à¥à¤µà¤šà¥à¤› à¤­à¤¾à¤°à¤¤": "à¤¸à¥à¤µà¤šà¥à¤› à¤­à¤¾à¤°à¤¤ à¤®à¤¿à¤¶à¤¨",
    r"\bSBM\b": "à¤¸à¥à¤µà¤šà¥à¤› à¤­à¤¾à¤°à¤¤ à¤®à¤¿à¤¶à¤¨",
    r"à¤œà¤¨ à¤§à¤¨": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤œà¤¨ à¤§à¤¨ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"\bJan Dhan\b": "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤œà¤¨ à¤§à¤¨ à¤¯à¥‹à¤œà¤¨à¤¾",
    r"\bGST\b": "GST",
}

TARGET_GROUP_KEYWORDS = {
    "à¤®à¤¹à¤¿à¤²à¤¾": "à¤®à¤¹à¤¿à¤²à¤¾",
    "à¤®à¤¹à¤¿à¤²à¤¾à¤“à¤‚": "à¤®à¤¹à¤¿à¤²à¤¾",
    "à¤¨à¤¾à¤°à¥€": "à¤®à¤¹à¤¿à¤²à¤¾",
    "à¤¯à¥à¤µà¤¾": "à¤¯à¥à¤µà¤¾",
    "à¤¯à¥à¤µà¤¾à¤“à¤‚": "à¤¯à¥à¤µà¤¾",
    "à¤•à¤¿à¤¸à¤¾à¤¨": "à¤•à¤¿à¤¸à¤¾à¤¨",
    "à¤•à¤¿à¤¸à¤¾à¤¨à¥‹à¤‚": "à¤•à¤¿à¤¸à¤¾à¤¨",
    "à¤–à¥‡à¤¤à¥€": "à¤•à¤¿à¤¸à¤¾à¤¨",
    "à¤›à¤¾à¤¤à¥à¤°": "à¤›à¤¾à¤¤à¥à¤°",
    "à¤µà¤¿à¤¦à¥à¤¯à¤¾à¤°à¥à¤¥à¥€": "à¤›à¤¾à¤¤à¥à¤°",
    "à¤¸à¥à¤Ÿà¥‚à¤¡à¥‡à¤‚à¤Ÿ": "à¤›à¤¾à¤¤à¥à¤°",
    "à¤®à¤œà¤¦à¥‚à¤°": "à¤®à¤œà¤¼à¤¦à¥‚à¤°",
    "à¤®à¤œà¤¦à¥‚à¤°à¥‹à¤‚": "à¤®à¤œà¤¼à¤¦à¥‚à¤°",
    "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°à¥€": "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°à¥€",
    "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°à¤¿à¤¯à¥‹à¤‚": "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°à¥€",
    "à¤—à¤°à¥€à¤¬": "à¤—à¤°à¥€à¤¬",
    "à¤†à¤°à¥à¤¥à¤¿à¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤•à¤®à¤œà¥‹à¤°": "à¤—à¤°à¥€à¤¬",
    "à¤¬à¥à¤œà¥à¤°à¥à¤—": "à¤¬à¥à¤œà¤¼à¥à¤°à¥à¤—",
    "à¤µà¤°à¤¿à¤·à¥à¤  à¤¨à¤¾à¤—à¤°à¤¿à¤•": "à¤¬à¥à¤œà¤¼à¥à¤°à¥à¤—",
    "à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤•à¤°à¥à¤®à¤šà¤¾à¤°à¥€": "à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤•à¤°à¥à¤®à¤šà¤¾à¤°à¥€",
    "à¤¶à¤¾à¤¸à¤•à¥€à¤¯ à¤•à¤°à¥à¤®à¤šà¤¾à¤°à¥€": "à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤•à¤°à¥à¤®à¤šà¤¾à¤°à¥€",
}

COMMUNITY_KEYWORDS = {
    "à¤¸à¤¾à¤¹à¥‚": "à¤¸à¤¾à¤¹à¥‚",
    "à¤—à¥‹à¤‚à¤¡": "à¤—à¥‹à¤‚à¤¡",
    "à¤†à¤¦à¤¿à¤µà¤¾à¤¸à¥€": "à¤†à¤¦à¤¿à¤µà¤¾à¤¸à¥€",
    "à¤—à¥‹à¤‚à¤¡à¤µà¤¾à¤¨à¤¾": "à¤—à¥‹à¤‚à¤¡",
    "à¤µà¥ˆà¤¶à¥à¤¯": "à¤µà¥ˆà¤¶à¥à¤¯",
    "à¤¬à¥à¤°à¤¾à¤¹à¥à¤®à¤£": "à¤¬à¥à¤°à¤¾à¤¹à¥à¤®à¤£",
    "à¤•à¥à¤°à¥à¤®à¥€": "à¤•à¥à¤°à¥à¤®à¥€",
    "à¤¤à¥‡à¤²à¥€": "à¤¤à¥‡à¤²à¥€",
    "à¤ à¤¾à¤•à¥à¤°": "à¤ à¤¾à¤•à¥à¤°",
    "à¤•à¥à¤¶à¤µà¤¾à¤¹à¤¾": "à¤•à¥à¤¶à¤µà¤¾à¤¹à¤¾",
    "à¤¦à¤²à¤¿à¤¤": "à¤¦à¤²à¤¿à¤¤",
    "à¤…à¤¨à¥à¤¸à¥‚à¤šà¤¿à¤¤ à¤œà¤¾à¤¤à¤¿": "à¤…à¤¨à¥à¤¸à¥‚à¤šà¤¿à¤¤ à¤œà¤¾à¤¤à¤¿",
    "à¤…à¤¨à¥à¤¸à¥‚à¤šà¤¿à¤¤ à¤œà¤¨à¤œà¤¾à¤¤à¤¿": "à¤…à¤¨à¥à¤¸à¥‚à¤šà¤¿à¤¤ à¤œà¤¨à¤œà¤¾à¤¤à¤¿",
    "à¤“à¤¬à¥€à¤¸à¥€": "à¤“à¤¬à¥€à¤¸à¥€",
    "à¤®à¥à¤¸à¥à¤²à¤¿à¤®": "à¤®à¥à¤¸à¥à¤²à¤¿à¤®",
    "à¤‡à¤¸à¥à¤²à¤¾à¤®": "à¤®à¥à¤¸à¥à¤²à¤¿à¤®",
    "à¤ˆà¤¸à¤¾à¤ˆ": "à¤ˆà¤¸à¤¾à¤ˆ",
    "à¤•à¥à¤°à¤¿à¤¶à¥à¤šà¤¿à¤¯à¤¨": "à¤ˆà¤¸à¤¾à¤ˆ",
    "à¤¸à¤¿à¤–": "à¤¸à¤¿à¤–",
    "à¤œà¥ˆà¤¨": "à¤œà¥ˆà¤¨",
    "à¤¬à¥Œà¤¦à¥à¤§": "à¤¬à¥Œà¤¦à¥à¤§",
}

ORG_KEYWORDS = {
    "à¤­à¤¾à¤œà¤ªà¤¾": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤œà¤¨à¤¤à¤¾ à¤ªà¤¾à¤°à¥à¤Ÿà¥€",
    "BJP": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤œà¤¨à¤¤à¤¾ à¤ªà¤¾à¤°à¥à¤Ÿà¥€",
    "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤œà¤¨à¤¤à¤¾ à¤ªà¤¾à¤°à¥à¤Ÿà¥€": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤œà¤¨à¤¤à¤¾ à¤ªà¤¾à¤°à¥à¤Ÿà¥€",
    "à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸",
    "INC": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸",
    "Indian National Congress": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸",
    "RSS": "à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤¸à¥à¤µà¤¯à¤‚à¤¸à¥‡à¤µà¤• à¤¸à¤‚à¤˜",
    "à¤†à¤°à¤à¤¸à¤à¤¸": "à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤¸à¥à¤µà¤¯à¤‚à¤¸à¥‡à¤µà¤• à¤¸à¤‚à¤˜",
    "à¤¸à¤°à¤•à¤¾à¤°": "à¤¸à¤°à¤•à¤¾à¤°",
    "à¤•à¥‡à¤‚à¤¦à¥à¤° à¤¸à¤°à¤•à¤¾à¤°": "à¤•à¥‡à¤‚à¤¦à¥à¤° à¤¸à¤°à¤•à¤¾à¤°",
    "à¤°à¤¾à¤œà¥à¤¯ à¤¸à¤°à¤•à¤¾à¤°": "à¤°à¤¾à¤œà¥à¤¯ à¤¸à¤°à¤•à¤¾à¤°",
    "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤¸à¥‡à¤¨à¤¾": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤¸à¥‡à¤¨à¤¾",
    "Indian Army": "à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤¸à¥‡à¤¨à¤¾",
}

# Extended canonical locations
CANONICAL_LOCATIONS: Dict[str, Dict[str, Any]] = {
    "à¤°à¤¾à¤¯à¤—à¤¢à¤¼": {"canonical": "à¤°à¤¾à¤¯à¤—à¤¢à¤¼", "aliases": ["à¤°à¤¾à¤¯à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¥", "Raigarh", "Raigarhh"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¤¢à¤¼ à¤œà¤¿à¤²à¤¾"]},
    "Raigarh": {"canonical": "à¤°à¤¾à¤¯à¤—à¤¢à¤¼", "aliases": ["à¤°à¤¾à¤¯à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¥", "Raigarh", "Raigarhh"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¤¢à¤¼ à¤œà¤¿à¤²à¤¾"]},
    "à¤–à¤°à¤¸à¤¿à¤¯à¤¾": {"canonical": "à¤–à¤°à¤¸à¤¿à¤¯à¤¾", "aliases": ["à¤–à¤°à¤¸à¤¿à¤¯à¤¾", "Kharsia", "Kharsiya"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¤¢à¤¼ à¤œà¤¿à¤²à¤¾", "à¤–à¤°à¤¸à¤¿à¤¯à¤¾ à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾"]},
    "Kharsia": {"canonical": "à¤–à¤°à¤¸à¤¿à¤¯à¤¾", "aliases": ["à¤–à¤°à¤¸à¤¿à¤¯à¤¾", "Kharsia", "Kharsiya"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤—à¤¢à¤¼ à¤œà¤¿à¤²à¤¾", "à¤–à¤°à¤¸à¤¿à¤¯à¤¾ à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾"]},
    "à¤°à¤¾à¤¯à¤ªà¥à¤°": {"canonical": "à¤°à¤¾à¤¯à¤ªà¥à¤°", "aliases": ["à¤°à¤¾à¤¯à¤ªà¥à¤°", "Raipur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Raipur": {"canonical": "à¤°à¤¾à¤¯à¤ªà¥à¤°", "aliases": ["à¤°à¤¾à¤¯à¤ªà¥à¤°", "Raipur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤¨à¤¯à¤¾ à¤°à¤¾à¤¯à¤ªà¥à¤°": {"canonical": "à¤¨à¤¯à¤¾ à¤°à¤¾à¤¯à¤ªà¥à¤°", "aliases": ["à¤¨à¤¯à¤¾ à¤°à¤¾à¤¯à¤ªà¥à¤°", "New Raipur", "Naya Raipur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "New Raipur": {"canonical": "à¤¨à¤¯à¤¾ à¤°à¤¾à¤¯à¤ªà¥à¤°", "aliases": ["à¤¨à¤¯à¤¾ à¤°à¤¾à¤¯à¤ªà¥à¤°", "New Raipur", "Naya Raipur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤¯à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤°": {"canonical": "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤°", "aliases": ["à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤°", "Bilaspur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Bilaspur": {"canonical": "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤°", "aliases": ["à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤°", "Bilaspur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤•à¥‹à¤°à¤¬à¤¾": {"canonical": "à¤•à¥‹à¤°à¤¬à¤¾", "aliases": ["à¤•à¥‹à¤°à¤¬à¤¾", "Korba"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤°à¤¬à¤¾ à¤œà¤¿à¤²à¤¾"]},
    "Korba": {"canonical": "à¤•à¥‹à¤°à¤¬à¤¾", "aliases": ["à¤•à¥‹à¤°à¤¬à¤¾", "Korba"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤°à¤¬à¤¾ à¤œà¤¿à¤²à¤¾"]},
    "à¤°à¤¤à¤¨à¤ªà¥à¤°": {"canonical": "à¤°à¤¤à¤¨à¤ªà¥à¤°", "aliases": ["à¤°à¤¤à¤¨à¤ªà¥à¤°", "Ratanpur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¿à¤²à¤¾à¤¸à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤¦à¥à¤°à¥à¤—": {"canonical": "à¤¦à¥à¤°à¥à¤—", "aliases": ["à¤¦à¥à¤°à¥à¤—", "Durg"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¥à¤°à¥à¤— à¤œà¤¿à¤²à¤¾"]},
    "Durg": {"canonical": "à¤¦à¥à¤°à¥à¤—", "aliases": ["à¤¦à¥à¤°à¥à¤—", "Durg"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¥à¤°à¥à¤— à¤œà¤¿à¤²à¤¾"]},
    "à¤­à¤¿à¤²à¤¾à¤ˆ": {"canonical": "à¤­à¤¿à¤²à¤¾à¤ˆ", "aliases": ["à¤­à¤¿à¤²à¤¾à¤ˆ", "Bhilai"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¥à¤°à¥à¤— à¤œà¤¿à¤²à¤¾"]},
    "Bhilai": {"canonical": "à¤­à¤¿à¤²à¤¾à¤ˆ", "aliases": ["à¤­à¤¿à¤²à¤¾à¤ˆ", "Bhilai"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¥à¤°à¥à¤— à¤œà¤¿à¤²à¤¾"]},
    "à¤…à¤‚à¤¬à¤¿à¤•à¤¾à¤ªà¥à¤°": {"canonical": "à¤…à¤‚à¤¬à¤¿à¤•à¤¾à¤ªà¥à¤°", "aliases": ["à¤…à¤‚à¤¬à¤¿à¤•à¤¾à¤ªà¥à¤°", "Ambikapur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤°à¤œà¤ªà¥à¤°/à¤¸à¤°à¤—à¥à¤œà¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤°"]},
    "Ambikapur": {"canonical": "à¤…à¤‚à¤¬à¤¿à¤•à¤¾à¤ªà¥à¤°", "aliases": ["à¤…à¤‚à¤¬à¤¿à¤•à¤¾à¤ªà¥à¤°", "Ambikapur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤°à¤œà¤ªà¥à¤°/à¤¸à¤°à¤—à¥à¤œà¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤°"]},
    "à¤¸à¥à¤°à¤œà¤ªà¥à¤°": {"canonical": "à¤¸à¥à¤°à¤œà¤ªà¥à¤°", "aliases": ["à¤¸à¥à¤°à¤œà¤ªà¥à¤°", "Surajpur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤°à¤œà¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Surajpur": {"canonical": "à¤¸à¥à¤°à¤œà¤ªà¥à¤°", "aliases": ["à¤¸à¥à¤°à¤œà¤ªà¥à¤°", "Surajpur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤°à¤œà¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤œà¤—à¤¦à¤²à¤ªà¥à¤°": {"canonical": "à¤œà¤—à¤¦à¤²à¤ªà¥à¤°", "aliases": ["à¤œà¤—à¤¦à¤²à¤ªà¥à¤°", "Jagdalpur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¸à¥à¤¤à¤° à¤œà¤¿à¤²à¤¾"]},
    "Jagdalpur": {"canonical": "à¤œà¤—à¤¦à¤²à¤ªà¥à¤°", "aliases": ["à¤œà¤—à¤¦à¤²à¤ªà¥à¤°", "Jagdalpur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¸à¥à¤¤à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ": {"canonical": "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ", "aliases": ["à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ", "Kondagaon"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ à¤œà¤¿à¤²à¤¾"]},
    "Kondagaon": {"canonical": "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ", "aliases": ["à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ", "Kondagaon"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤•à¥‹à¤‚à¤¡à¤¾à¤—à¤¾à¤à¤µ à¤œà¤¿à¤²à¤¾"]},
    "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤°": {"canonical": "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤°", "aliases": ["à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤°", "Narayanpur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Narayanpur": {"canonical": "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤°", "aliases": ["à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤°", "Narayanpur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°": {"canonical": "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°", "aliases": ["à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°", "Janjgir"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°-à¤šà¤‚à¤ªà¤¾ à¤œà¤¿à¤²à¤¾"]},
    "Janjgir": {"canonical": "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°", "aliases": ["à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°", "Janjgir"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°-à¤šà¤‚à¤ªà¤¾ à¤œà¤¿à¤²à¤¾"]},
    "à¤šà¤‚à¤ªà¤¾": {"canonical": "à¤šà¤‚à¤ªà¤¾", "aliases": ["à¤šà¤‚à¤ªà¤¾", "Champa"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤œà¤¾à¤‚à¤œà¤—à¥€à¤°-à¤šà¤‚à¤ªà¤¾ à¤œà¤¿à¤²à¤¾"]},
    "à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ": {"canonical": "à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ", "aliases": ["à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ", "Rajandgaon"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ à¤œà¤¿à¤²à¤¾"]},
    "Rajandgaon": {"canonical": "à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ", "aliases": ["à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ", "Rajandgaon"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤°à¤¾à¤œà¤¨à¤¾à¤‚à¤¦à¤—à¤¾à¤à¤µ à¤œà¤¿à¤²à¤¾"]},
    "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦": {"canonical": "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦", "aliases": ["à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦", "Mahasamund"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦ à¤œà¤¿à¤²à¤¾"]},
    "Mahasamund": {"canonical": "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦", "aliases": ["à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦", "Mahasamund"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤®à¤¹à¤¾à¤¸à¤®à¥à¤‚à¤¦ à¤œà¤¿à¤²à¤¾"]},
    "à¤§à¤®à¤¤à¤°à¥€": {"canonical": "à¤§à¤®à¤¤à¤°à¥€", "aliases": ["à¤§à¤®à¤¤à¤°à¥€", "Dhamtari"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤§à¤®à¤¤à¤°à¥€ à¤œà¤¿à¤²à¤¾"]},
    "Dhamtari": {"canonical": "à¤§à¤®à¤¤à¤°à¥€", "aliases": ["à¤§à¤®à¤¤à¤°à¥€", "Dhamtari"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤§à¤®à¤¤à¤°à¥€ à¤œà¤¿à¤²à¤¾"]},
    "à¤¬à¤¾à¤²à¥‹à¤¦": {"canonical": "à¤¬à¤¾à¤²à¥‹à¤¦", "aliases": ["à¤¬à¤¾à¤²à¥‹à¤¦", "Balod"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¾à¤²à¥‹à¤¦à¤œà¤¿à¤²à¤¾"]},
    "Balod": {"canonical": "à¤¬à¤¾à¤²à¥‹à¤¦", "aliases": ["à¤¬à¤¾à¤²à¥‹à¤¦", "Balod"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¤¾à¤²à¥‹à¤¦à¤œà¤¿à¤²à¤¾"]},
    "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦": {"canonical": "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦", "aliases": ["à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦", "Gariaband"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦ à¤œà¤¿à¤²à¤¾"]},
    "Gariaband": {"canonical": "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦", "aliases": ["à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦", "Gariaband"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤—à¤°à¤¿à¤¯à¤¾à¤¬à¤‚à¤¦ à¤œà¤¿à¤²à¤¾"]},
    "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤°": {"canonical": "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤°", "aliases": ["à¤¬à¥€à¤œà¤¾à¤ªà¥à¤°", "Bijapur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "Bijapur": {"canonical": "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤°", "aliases": ["à¤¬à¥€à¤œà¤¾à¤ªà¥à¤°", "Bijapur"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¬à¥€à¤œà¤¾à¤ªà¥à¤° à¤œà¤¿à¤²à¤¾"]},
    "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾": {"canonical": "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾", "aliases": ["à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾", "Dantewada"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾ à¤œà¤¿à¤²à¤¾"]},
    "Dantewada": {"canonical": "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾", "aliases": ["à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾", "Dantewada"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¦à¤‚à¤¤à¥‡à¤µà¤¾à¤¡à¤¼à¤¾ à¤œà¤¿à¤²à¤¾"]},
    "à¤¸à¥à¤•à¤®à¤¾": {"canonical": "à¤¸à¥à¤•à¤®à¤¾", "aliases": ["à¤¸à¥à¤•à¤®à¤¾", "Sukma"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤•à¤®à¤¾à¤œà¤¿à¤²à¤¾"]},
    "Sukma": {"canonical": "à¤¸à¥à¤•à¤®à¤¾", "aliases": ["à¤¸à¥à¤•à¤®à¤¾", "Sukma"], "hierarchy": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼", "à¤¸à¥à¤•à¤®à¤¾à¤œà¤¿à¤²à¤¾"]},
}

# -------------------------
# Feature extractors
# -------------------------

def normalize_event_type_base(raw_event_type_hi: Optional[str], text: str, schemes: List[str]) -> Tuple[str, float]:
    text_lower = text.lower()
    candidate: Optional[str] = None
    best_conf = 0.0

    # 1) keyword clusters
    for keywords, label in EVENT_KEYWORD_CLUSTERS:
        for kw in keywords:
            if kw.lower() in text_lower:
                base_conf = 0.80
                # Specific high-confidence categories
                if label in ("à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤¨à¤¿à¤• à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤¬à¥ˆà¤ à¤•", "à¤œà¤¨à¤¸à¤®à¥à¤ªà¤°à¥à¤• / à¤œà¤¨à¤¦à¤°à¥à¤¶à¤¨", "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸", "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ", "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾"):
                    base_conf = 0.88
                
                if base_conf > best_conf:
                    best_conf = base_conf
                    candidate = label
                break

    # 2) Use old hint if valid
    if raw_event_type_hi and raw_event_type_hi in ALLOWED_EVENT_TYPES_HI and raw_event_type_hi != "à¤…à¤¨à¥à¤¯":
        if candidate is None:
            candidate = raw_event_type_hi
            best_conf = max(best_conf, 0.75)
        elif raw_event_type_hi == candidate:
            best_conf = max(best_conf, 0.93)

    # 3) schemes + no candidate -> Yojna
    if (candidate is None or candidate == "à¤…à¤¨à¥à¤¯") and schemes:
        candidate = "à¤¯à¥‹à¤œà¤¨à¤¾ à¤˜à¥‹à¤·à¤£à¤¾"
        best_conf = max(best_conf, 0.8)

    # 4) fallback
    if candidate is None:
        candidate = "à¤…à¤¨à¥à¤¯"
        best_conf = max(best_conf, 0.45)

    return candidate, best_conf

def extract_schemes(text: str) -> Tuple[List[str], float]:
    schemes = set()
    for pattern, canonical in SCHEME_PATTERNS.items():
        if re.search(pattern, text, flags=re.IGNORECASE):
            schemes.add(canonical)
    if not schemes:
        return [], 0.0
    conf = min(0.96, 0.65 + 0.08 * len(schemes))
    return sorted(schemes), conf

def extract_target_groups(text: str) -> Tuple[List[str], float]:
    groups = set()
    for kw, canonical in TARGET_GROUP_KEYWORDS.items():
        if kw in text:
            groups.add(canonical)
    if not groups:
        return [], 0.0
    conf = min(0.9, 0.65 + 0.05 * len(groups))
    return sorted(groups), conf

def extract_communities(text: str) -> Tuple[List[str], float]:
    communities = set()
    for kw, canonical in COMMUNITY_KEYWORDS.items():
        if kw in text:
            communities.add(canonical)
    if not communities:
        return [], 0.0
    conf = min(0.9, 0.65 + 0.05 * len(communities))
    return sorted(communities), conf

def extract_orgs(text: str) -> Tuple[List[str], float]:
    orgs = set()
    lowered = text.lower()
    for kw, canonical in ORG_KEYWORDS.items():
        if kw.lower() in lowered:
            orgs.add(canonical)
    if not orgs:
        return [], 0.0
    conf = min(0.9, 0.65 + 0.05 * len(orgs))
    return sorted(orgs), conf

def extract_hashtags(text: str) -> List[str]:
    return re.findall(r"#(\w+)", text)

def make_word_buckets(text: str) -> Tuple[List[str], float]:
    buckets: List[str] = []
    for tag in extract_hashtags(text):
        t = tag.lower()
        if "pmawas" in t or "pmay" in t:
            buckets.append("PM à¤†à¤µà¤¾à¤¸ à¤¯à¥‹à¤œà¤¨à¤¾")
        elif "ayushman" in t:
            buckets.append("à¤†à¤¯à¥à¤·à¥à¤®à¤¾à¤¨ à¤­à¤¾à¤°à¤¤")
        elif "gst" in t:
            buckets.append("GST")
        elif "kisan" in t or "farmer" in t:
            buckets.append("à¤•à¥ƒà¤·à¤¿ / à¤•à¤¿à¤¸à¤¾à¤¨")
        elif "youth" in t or "yuva" in t:
            buckets.append("à¤¯à¥à¤µà¤¾")
        elif "mahila" in t or "women" in t:
            buckets.append("à¤®à¤¹à¤¿à¤²à¤¾ à¤¸à¤¶à¤•à¥à¤¤à¤¿à¤•à¤°à¤£")

    topic_map = [
        (["à¤•à¤¿à¤¸à¤¾à¤¨", "à¤«à¤¸à¤²", "à¤–à¥‡à¤¤à¥€", "à¤•à¥ƒà¤·à¤¿"], "à¤•à¥ƒà¤·à¤¿ / à¤•à¤¿à¤¸à¤¾à¤¨"),
        (["à¤®à¤¹à¤¿à¤²à¤¾", "à¤®à¤¹à¤¿à¤²à¤¾à¤“à¤‚", "à¤¨à¤¾à¤°à¥€"], "à¤®à¤¹à¤¿à¤²à¤¾ à¤¸à¤¶à¤•à¥à¤¤à¤¿à¤•à¤°à¤£"),
        (["à¤¶à¤¿à¤•à¥à¤·à¤¾", "à¤¸à¥à¤•à¥‚à¤²", "à¤•à¥‰à¤²à¥‡à¤œ", "à¤µà¤¿à¤¦à¥à¤¯à¤¾à¤²à¤¯"], "à¤¶à¤¿à¤•à¥à¤·à¤¾"),
        (["à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯", "à¤…à¤¸à¥à¤ªà¤¤à¤¾à¤²", "à¤šà¤¿à¤•à¤¿à¤¤à¥à¤¸à¤¾", "à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤¶à¤¿à¤µà¤¿à¤°"], "à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯"),
        (["à¤¬à¤¿à¤œà¤²à¥€", "à¤°à¥‹à¤¶à¤¨à¥€", "à¤µà¤¿à¤¦à¥à¤¯à¥à¤¤"], "à¤¬à¤¿à¤œà¤²à¥€"),
        (["à¤¸à¤¡à¤¼à¤•", "à¤®à¤¾à¤°à¥à¤—", "highway", "à¤ªà¥à¤²"], "à¤¸à¤¡à¤¼à¤• / à¤‡à¤¨à¥à¤«à¥à¤°à¤¾"),
        (["à¤¨à¥Œà¤•à¤°à¥€", "à¤°à¥‹à¤œà¤¼à¤—à¤¾à¤°", "à¤°à¥‹à¤œà¤—à¤¾à¤°"], "à¤°à¥‹à¤œà¤¼à¤—à¤¾à¤°"),
        (["à¤¯à¥à¤µà¤¾", "à¤¯à¥à¤µà¤¾ à¤¸à¤®à¥à¤®à¥‡à¤²à¤¨"], "à¤¯à¥à¤µà¤¾"),
        (["à¤‰à¤¦à¥à¤¯à¤®à¥€", "à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°", "à¤‰à¤¦à¥à¤¯à¥‹à¤—"], "à¤‰à¤¦à¥à¤¯à¥‹à¤— / à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°"),
    ]
    lower = text.lower()
    for words, bucket in topic_map:
        if any(w.lower() in lower for w in words):
            buckets.append(bucket)

    buckets = sorted(set(buckets))
    if not buckets:
        return [], 0.0
    conf = min(0.92, 0.55 + 0.05 * len(buckets))
    return buckets, conf

# -------------------------
# Location helpers
# -------------------------

def extract_inline_location_candidates(text: str) -> List[str]:
    candidates: List[str] = []
    patterns = [
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤œà¤¿à¤²à¤¾", r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¬à¥à¤²à¥‰à¤•", r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¨à¤—à¤° à¤¨à¤¿à¤—à¤®",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¨à¤—à¤° à¤ªà¤¾à¤²à¤¿à¤•à¤¾", r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤¨à¤—à¤° à¤ªà¤‚à¤šà¤¾à¤¯à¤¤",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤—à¥à¤°à¤¾à¤® à¤ªà¤‚à¤šà¤¾à¤¯à¤¤", r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤—à¥à¤°à¤¾à¤®",
        r"([à¤…-à¤¹à¥˜-à¥ŸA-Za-z]+)\s+à¤—à¤¾à¤à¤µ",
    ]
    for pat in patterns:
        for m in re.finditer(pat, text):
            name = m.group(1).strip()
            if len(name) >= 2:
                candidates.append(name)
    return candidates

def normalize_location(text: str, old_location: Optional[Dict[str, Any]]) -> Tuple[Optional[Dict[str, Any]], float]:
    candidates: List[str] = []
    if old_location:
        can = old_location.get("canonical") or old_location.get("district")
        if can: candidates.append(str(can))
        aliases = old_location.get("aliases") or []
        for a in aliases:
            if a: candidates.append(str(a))

    for key in CANONICAL_LOCATIONS.keys():
        if key in text: candidates.append(key)

    lower = text.lower()
    for key in CANONICAL_LOCATIONS.keys():
        if key.lower() in lower: candidates.append(key)

    candidates.extend(extract_inline_location_candidates(text))

    if not candidates:
        return None, 0.0

    count = Counter(candidates)
    best_raw, _ = count.most_common(1)[0]
    loc_info = CANONICAL_LOCATIONS.get(best_raw)

    if not loc_info:
        loc_obj = {
            "district": None, "assembly": None, "block": None, "gp": None,
            "village": None, "ulb": None, "zone": None, "ward": None,
            "canonical_key": None, "canonical": best_raw, "aliases": [best_raw],
            "hierarchy_path": ["à¤›à¤¤à¥à¤¤à¥€à¤¸à¤—à¤¢à¤¼"], "visit_count": 1,
        }
        return loc_obj, 0.55

    canonical = loc_info["canonical"]
    aliases = sorted(set(loc_info.get("aliases", []) + [best_raw]))
    hierarchy = loc_info.get("hierarchy", [])
    district = None
    assembly = None

    for level in hierarchy:
        if "à¤œà¤¿à¤²à¤¾" in level: district = level.replace(" à¤œà¤¿à¤²à¤¾", "")
        if "à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾" in level: assembly = level.replace(" à¤µà¤¿à¤§à¤¾à¤¨à¤¸à¤­à¤¾", "")

    loc_obj = {
        "district": district, "assembly": assembly, "block": None, "gp": None,
        "village": None, "ulb": None, "zone": None, "ward": None,
        "canonical_key": f"CG_{canonical}", "canonical": canonical,
        "aliases": aliases, "hierarchy_path": hierarchy, "visit_count": 1,
    }
    return loc_obj, 0.88

# -------------------------
# Confidence (V6 Enhanced)
# -------------------------

def compute_confidence_base(c_event: float, c_location: float, schemes: List[str], event_type: str, location_obj: Optional[Dict[str, Any]]) -> float:
    good_event = event_type != "à¤…à¤¨à¥à¤¯"
    good_loc = bool(location_obj and location_obj.get("canonical"))

    base = 0.4
    if good_event: base += 0.25
    if good_loc: base += 0.2
    if schemes: base += 0.05

    score = base * 0.7 + ((c_event + c_location) / 2) * 0.3
    return min(0.99, max(0.0, score))

def compute_confidence_v6(base_conf: float, pd6_extra: Dict[str, Any], base_pd: Dict[str, Any]) -> float:
    """
V6 Signal Multiplier: Boosts confidence based on signal triangulation.
    """
    final_conf = base_conf
    bonus = pd6_extra.get("rescue_confidence_bonus", 0.0)
    final_conf += bonus

    event_type = pd6_extra.get("event_type") or base_pd.get("event_type")
    has_location = bool(base_pd.get("location") and base_pd["location"].get("canonical"))
    has_person = len(base_pd.get("people_mentioned", [])) > 0
    content_mode = pd6_extra.get("content_mode")

    # 1. HIGH PRECISION EVENT BOOST
    # These events are rarely false positives if keywords match
    HIGH_PRECISION_EVENTS = [
        "à¤¶à¥‹à¤• à¤¸à¤‚à¤¦à¥‡à¤¶", "à¤œà¤¨à¥à¤®à¤¦à¤¿à¤¨ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾", "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸", 
        "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ", "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾"
    ]
    if event_type in HIGH_PRECISION_EVENTS:
        final_conf = max(final_conf, 0.92)

    # 2. TRIANGULATION BONUS (Event + Person + Location)
    if has_location and has_person and event_type != "à¤…à¤¨à¥à¤¯":
        final_conf += 0.15

    # 3. DUAL SIGNAL BONUS
    elif (has_location or has_person) and event_type != "à¤…à¤¨à¥à¤¯":
        final_conf += 0.08

    # 4. SPECIFIC CONTEXT BOOSTS
    if event_type == "à¤¬à¥ˆà¤ à¤•" and content_mode == "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®":
        final_conf += 0.05

    # 5. Rescue Confidence Integrity
    if pd6_extra.get("is_rescued_other"):
        # If rescued, ensure it meets a decent threshold
        final_conf = max(final_conf, 0.85)

    return round(min(final_conf, 0.99), 3)

def decide_review_status(conf: float) -> Tuple[str, bool]:
    if conf >= 0.9: return "auto_approved", False
    if conf >= 0.75: return "pending", False
    return "pending", True

# -------------------------
# "à¤…à¤¨à¥à¤¯" Rescue â€“ V6 Logic
# -------------------------

def _looks_like_sports_tweet(text_l: str) -> bool:
    SPORTS_KW = ["à¤®à¥ˆà¤š", "à¤œà¥€à¤¤", "à¤µà¤¿à¤œà¤¯", "à¤Ÿà¥€à¤® à¤‡à¤‚à¤¡à¤¿à¤¯à¤¾", "world cup", "à¤Ÿà¥€20", "ipl", "medal", "à¤ªà¤¦à¤•"]
    return any(kw in text_l for kw in SPORTS_KW)

def _looks_like_policy_statement(text_l: str) -> bool:
    POLICY_KW = ["à¤¸à¤¬à¤•à¤¾ à¤¸à¤¾à¤¥", "à¤µà¤¿à¤•à¤¸à¤¿à¤¤ à¤­à¤¾à¤°à¤¤", "à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€", "à¤—à¤¾à¤°à¤‚à¤Ÿà¥€", "à¤¡à¤¬à¤² à¤‡à¤‚à¤œà¤¨", "à¤•à¤¾à¤‚à¤—à¥à¤°à¥‡à¤¸", "à¤µà¤¿à¤ªà¤•à¥à¤·"]
    return any(kw in text_l for kw in POLICY_KW)

def _looks_like_security_context(text_l: str) -> bool:
    SECURITY_KW = ["à¤®à¤¾à¤“à¤µà¤¾à¤¦à¥€", "à¤¨à¤•à¥à¤¸à¤²", "à¤†à¤¤à¤‚à¤•", "à¤¶à¤¹à¥€à¤¦", "à¤œà¤µà¤¾à¤¨", "police", "à¤¬à¤¸à¥à¤¤à¤°"]
    return any(kw in text_l for kw in SECURITY_KW)

def _looks_like_pure_greetings(text_l: str) -> bool:
    GREET_KW = ["à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾", "à¤¬à¤§à¤¾à¤ˆ", "à¤®à¥à¤¬à¤¾à¤°à¤•", "congratulations"]
    FESTIVAL_HINTS = ["à¤¦à¥€à¤ªà¤¾à¤µà¤²à¥€", "à¤¹à¥‹à¤²à¥€", "à¤°à¤•à¥à¤·à¤¾ à¤¬à¤‚à¤§à¤¨", "à¤¸à¥à¤µà¤¤à¤‚à¤¤à¥à¤°à¤¤à¤¾ à¤¦à¤¿à¤µà¤¸"]
    has_greet = any(kw in text_l for kw in GREET_KW) or any(kw in text_l for kw in FESTIVAL_HINTS)
    EVENT_HINTS = ["à¤¬à¥ˆà¤ à¤•", "à¤°à¥ˆà¤²à¥€", "à¤‰à¤¦à¥à¤˜à¤¾à¤Ÿà¤¨"]
    return has_greet and not any(e in text_l for e in EVENT_HINTS)

def _looks_like_digital_only(text_l: str, pd: Dict[str, Any]) -> bool:
    loc = pd.get("location") or {}
    DIGITAL_KW = ["online", "live", "à¤œà¥à¤¡à¤¼à¥‡à¤‚", "link"]
    return (not loc.get("canonical")) and any(kw in text_l for kw in DIGITAL_KW)

def _looks_like_relief_humanitarian(text_l: str) -> bool:
    RELIEF_KW = ["à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾", "à¤°à¤¾à¤¹à¤¤", "à¤¬à¤¾à¤¢à¤¼", "à¤¸à¥‚à¤–à¤¾", "à¤®à¥à¤†à¤µà¤œà¤¾", "à¤•à¥à¤·à¤¤à¤¿à¤ªà¥‚à¤°à¥à¤¤à¤¿"]
    return any(kw in text_l for kw in RELIEF_KW)

# Other heuristics from V5 preserved
def _looks_like_scheme_impl(text_l: str, schemes: List[str]) -> bool:
    return bool(schemes) and ("à¤²à¤¾à¤­à¤¾à¤°à¥à¤¥à¥€" in text_l or "à¤µà¤¿à¤¤à¤°à¤£" in text_l)

def rescue_other_events_v6(text: str, base_pd: Dict[str, Any]) -> Dict[str, Any]:
    """
V6 Rescue Logic: Maps detected patterns to specific V6 categories.
    """
    text_l = text.lower()
    original_event = base_pd.get("event_type")
    schemes = base_pd.get("schemes_mentioned") or []

    pd_extra: Dict[str, Any] = {
        "event_type": original_event,
        "content_mode": None,
        "is_other_original": (original_event == "à¤…à¤¨à¥à¤¯"),
        "is_rescued_other": False,
        "rescue_tag": None,
        "rescue_confidence_bonus": 0.0,
    }

    # 1. Sports -> Now maps to "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ"
    if _looks_like_sports_tweet(text_l):
        pd_extra["content_mode"] = "à¤–à¥‡à¤² / à¤‰à¤ªà¤²à¤¬à¥à¤§à¤¿ à¤ªà¤° à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾"
        if original_event == "à¤…à¤¨à¥à¤¯":
            pd_extra["event_type"] = "à¤–à¥‡à¤² / à¤—à¥Œà¤°à¤µ"
            pd_extra["is_rescued_other"] = True
            pd_extra["rescue_tag"] = "sports_v6"
            pd_extra["rescue_confidence_bonus"] = 0.18
        return pd_extra

    # 2. Security -> Now maps to "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸"
    if _looks_like_security_context(text_l):
        pd_extra["content_mode"] = "à¤¨à¥€à¤¤à¤¿ / à¤µà¤•à¥à¤¤à¤µà¥à¤¯"
        if original_event == "à¤…à¤¨à¥à¤¯":
            pd_extra["event_type"] = "à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¸à¥à¤°à¤•à¥à¤·à¤¾ / à¤ªà¥à¤²à¤¿à¤¸"
            pd_extra["is_rescued_other"] = True
            pd_extra["rescue_tag"] = "security_v6"
            pd_extra["rescue_confidence_bonus"] = 0.20
        return pd_extra

    # 3. Relief -> Now maps to "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾"
    if _looks_like_relief_humanitarian(text_l):
        pd_extra["content_mode"] = "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®"
        if original_event == "à¤…à¤¨à¥à¤¯":
            pd_extra["event_type"] = "à¤†à¤ªà¤¦à¤¾ / à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾"
            pd_extra["is_rescued_other"] = True
            pd_extra["rescue_tag"] = "disaster_v6"
            pd_extra["rescue_confidence_bonus"] = 0.18
        return pd_extra

    # 4. Policy -> Now maps to "à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤µà¤•à¥à¤¤à¤µà¥à¤¯"
    if _looks_like_policy_statement(text_l):
        pd_extra["content_mode"] = "à¤¨à¥€à¤¤à¤¿ / à¤µà¤•à¥à¤¤à¤µà¥à¤¯"
        if original_event == "à¤…à¤¨à¥à¤¯":
            pd_extra["event_type"] = "à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤µà¤•à¥à¤¤à¤µà¥à¤¯"
            pd_extra["is_rescued_other"] = True
            pd_extra["rescue_tag"] = "political_v6"
            pd_extra["rescue_confidence_bonus"] = 0.15
        return pd_extra

    # 5. Scheme Implementation -> "à¤¯à¥‹à¤œà¤¨à¤¾ à¤˜à¥‹à¤·à¤£à¤¾"
    if _looks_like_scheme_impl(text_l, schemes):
        pd_extra["content_mode"] = "à¤®à¥ˆà¤¦à¤¾à¤¨-à¤¸à¥à¤¤à¤° à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®"
        if original_event == "à¤…à¤¨à¥à¤¯":
            pd_extra["event_type"] = "à¤¯à¥‹à¤œà¤¨à¤¾ à¤˜à¥‹à¤·à¤£à¤¾"
            pd_extra["is_rescued_other"] = True
            pd_extra["rescue_tag"] = "scheme_impl"
            pd_extra["rescue_confidence_bonus"] = 0.18
        return pd_extra

    # 6. Pure Greetings -> "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾ / à¤¬à¤§à¤¾à¤ˆ"
    if _looks_like_pure_greetings(text_l):
        pd_extra["content_mode"] = "à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾à¤à¤ / à¤ªà¤°à¥à¤µ"
        if original_event == "à¤…à¤¨à¥à¤¯":
            pd_extra["event_type"] = "à¤¶à¥à¤­à¤•à¤¾à¤®à¤¨à¤¾ / à¤¬à¤§à¤¾à¤ˆ"
            pd_extra["is_rescued_other"] = True
            pd_extra["rescue_tag"] = "greetings"
            pd_extra["rescue_confidence_bonus"] = 0.10
        return pd_extra

    # 7. Digital -> "à¤…à¤¨à¥à¤¯" (but classified mode)
    if _looks_like_digital_only(text_l, base_pd):
        pd_extra["content_mode"] = "à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² / à¤¸à¥‹à¤¶à¤²-à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤ªà¥‹à¤¸à¥à¤Ÿ"
        if original_event == "à¤…à¤¨à¥à¤¯":
            pd_extra["is_rescued_other"] = True
            pd_extra["rescue_tag"] = "digital"
            pd_extra["rescue_confidence_bonus"] = 0.05
        return pd_extra

    # Fallback
    pd_extra["content_mode"] = "à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² / à¤¸à¥‹à¤¶à¤²-à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤ªà¥‹à¤¸à¥à¤Ÿ"
    return pd_extra

# -------------------------
# Parsing Driver
# -------------------------

def parse_tweet_v6(record: Dict[str, Any]) -> Dict[str, Any]:
    text = record.get("raw_text") or record.get("text") or ""
    created_at = record.get("created_at")
    old_pd = record.get("parsed_data_v5") or record.get("parsed_data_v4") or {}

    # 1. Base Parse (Extraction + Keyword Clustering)
    schemes, c_schemes = extract_schemes(text)
    word_buckets, _ = make_word_buckets(text)
    target_groups, _ = extract_target_groups(text)
    communities, _ = extract_communities(text)
    orgs, _ = extract_orgs(text)

    # Base Event Detection (includes new V6 clusters)
    event_type, c_event = normalize_event_type_base(old_pd.get("event_type"), text, schemes)
    location_obj, c_location = normalize_location(text, old_pd.get("location"))

    base_confidence = compute_confidence_base(c_event, c_location, schemes, event_type, location_obj)

    base_pd = {
        "event_type": event_type,
        "event_date": created_at[:10] if created_at else None,
        "location": location_obj,
        "people_mentioned": old_pd.get("people_mentioned", []),
        "schemes_mentioned": schemes,
        "word_buckets": word_buckets,
        "target_groups": target_groups,
        "communities": communities,
        "organizations": orgs,
        "confidence": base_confidence
    }

    # 2. Rescue / Classification Layer (V6)
    pd_extra = rescue_other_events_v6(text, base_pd)

    # 3. Final Confidence (Signal Multiplier)
    final_conf = compute_confidence_v6(base_confidence, pd_extra, base_pd)
    review_status, needs_review = decide_review_status(final_conf)

    parsed_data_v6 = {
        **base_pd,
        "event_type": pd_extra["event_type"],
        "confidence": final_conf,
        "review_status": review_status,
        "needs_review": needs_review,
        "content_mode": pd_extra["content_mode"],
        "is_rescued_other": pd_extra["is_rescued_other"],
        "rescue_tag": pd_extra["rescue_tag"]
    }

    return {
        "tweet_id": record.get("tweet_id"),
        "created_at": created_at,
        "raw_text": text,
        "parsed_data_v6": parsed_data_v6,
        "metadata_v6": {"model": "rule-engine-v6-optimised"}
    }

def reparse_file_v6(input_path: Path, output_path: Path) -> None:
    print(f"ðŸš€ Starting V6 Parsing on {input_path}...")
    total = 0
    stats = Counter()
    
    with input_path.open("r", encoding="utf-8") as fin, output_path.open("w", encoding="utf-8") as fout:
        for line in fin:
            if not line.strip(): continue
            try:
                rec = json.loads(line)
            except:
                continue

            total += 1
            new_rec = parse_tweet_v6(rec)
            pd = new_rec["parsed_data_v6"]
            
            # Stats
            if pd["confidence"] >= 0.9: stats["High Conf (>=0.9)"] += 1
            elif pd["confidence"] >= 0.7: stats["Med Conf (0.7-0.9)"] += 1
            else: stats["Low Conf (<0.7)"] += 1
            
            stats[f"Event: {pd['event_type']}"] += 1
            if pd["is_rescued_other"]: stats["Rescued Tweets"] += 1
            
            fout.write(json.dumps(new_rec, ensure_ascii=False) + "\n")

    print(f"\nâœ… V6 Complete. Total: {total}")
    print(f"   High Conf: {stats['High Conf (>=0.9)']}")
    print(f"   Rescued: {stats['Rescued Tweets']}")
    print("\nEvent Distribution:")
    for k, v in stats.most_common(20):
        if k.startswith("Event:"): print(f"   {k}: {v}")

if __name__ == "__main__":
    import sys
    inp = Path(sys.argv[1]) if len(sys.argv) > 1 else DEFAULT_INPUT
    out = Path(sys.argv[2]) if len(sys.argv) > 2 else DEFAULT_OUTPUT
    reparse_file_v6(inp, out)
